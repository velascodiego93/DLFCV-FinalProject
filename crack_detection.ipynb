{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8c28ffa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "import os, json, glob\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3286d7a0",
   "metadata": {},
   "source": [
    "### **Data preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2988fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to remove unwanted labels from annotation JSON files.\n",
    "DROP_LABELS = {'Bearing', 'EJoint', 'Drainage', 'PEquipment', 'JTape', 'WConccor'}\n",
    "\n",
    "def clean_annotation(in_json_path: str, out_json_path: str, drop=DROP_LABELS) -> int:\n",
    "    \"\"\"Removes shapes whose 'label' is in DROP_LABELS. Returns # removed.\"\"\"\n",
    "    with open(in_json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        ann = json.load(f)\n",
    "\n",
    "    shapes = ann.get(\"shapes\", [])\n",
    "    kept = [s for s in shapes if s.get(\"label\") not in drop]\n",
    "    removed = len(shapes) - len(kept)\n",
    "    ann[\"shapes\"] = kept\n",
    "\n",
    "    os.makedirs(os.path.dirname(out_json_path), exist_ok=True)\n",
    "    with open(out_json_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(ann, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    return removed\n",
    "\n",
    "def batch_clean_annotation(in_ann_dir: str, out_ann_dir: str, pattern=\"*.json\") -> None:\n",
    "    jsons = glob.glob(os.path.join(in_ann_dir, pattern))\n",
    "    total_removed = 0\n",
    "    for jp in tqdm(jsons, desc=\"Cleaning annotations\", total=len(jsons)):\n",
    "        rel = os.path.relpath(jp, in_ann_dir)\n",
    "        outp = os.path.join(out_ann_dir, rel)\n",
    "        total_removed += clean_annotation(jp, outp)\n",
    "    print(f\"Done. Processed {len(jsons)} files. Removed {total_removed} shapes total.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb8189ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleaning annotations: 100%|██████████| 6935/6935 [00:02<00:00, 2351.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done. Processed 6935 files. Removed 5859 shapes total.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleaning annotations: 100%|██████████| 975/975 [00:00<00:00, 2085.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done. Processed 975 files. Removed 885 shapes total.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Clean dataset annotations\n",
    "pattern = \"*.json\"\n",
    "\n",
    "# Train\n",
    "in_ann_dir = \"/Users/diegovelasco/Desktop/Diego/FING/DLFCV-FinalProject/data/dacl10k_v2_devphase/annotations/train\"\n",
    "out_ann_dir = \"/Users/diegovelasco/Desktop/Diego/FING/DLFCV-FinalProject/data_clean/annotations/train\"\n",
    "batch_clean_annotation(in_ann_dir, out_ann_dir, pattern)\n",
    "\n",
    "# Validation\n",
    "in_ann_dir = \"/Users/diegovelasco/Desktop/Diego/FING/DLFCV-FinalProject/data/dacl10k_v2_devphase/annotations/validation\"\n",
    "out_ann_dir = \"/Users/diegovelasco/Desktop/Diego/FING/DLFCV-FinalProject/data_clean/annotations/validation\"\n",
    "batch_clean_annotation(in_ann_dir, out_ann_dir, pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e90b71",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing overlaps: 100%|██████████| 6935/6935 [04:23<00:00, 26.32it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed images: 6935\n",
      "Images with overlaps: 4042 (58.3%)\n",
      "Total overlapping pixels: 915524988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Function to draw annotations and compute overlaps\n",
    "def compute_overlap(img_path, ann_path, classes):\n",
    "    w, h = Image.open(img_path).size\n",
    "    # one boolean mask per class\n",
    "    planes = np.zeros((len(classes), h, w), dtype=bool)\n",
    "\n",
    "    with open(ann_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        ann = json.load(f)\n",
    "\n",
    "    # Loop over shapes (one shape is one mask)\n",
    "    for shp in ann.get(\"shapes\", []):\n",
    "        label = shp.get(\"label\", \"\")\n",
    "\n",
    "        # Skip unwanted labels (should not be present after cleaning)\n",
    "        if label not in classes:\n",
    "            continue\n",
    "\n",
    "        # Get points for each shape (mask)\n",
    "        idx = classes.index(label)\n",
    "        pts = shp.get(\"points\", [])\n",
    "\n",
    "        # Skip invalid polygons if they exist\n",
    "        if len(pts) < 3:\n",
    "            continue\n",
    "\n",
    "        # Generate mask for this polygon, draw it to a temporary image, and add it to the corresponding plane (accumulating all masks for that class)\n",
    "        poly = [(float(x), float(y)) for x, y in pts]\n",
    "        m = Image.new(\"1\", (w, h), 0)\n",
    "        ImageDraw.Draw(m).polygon(poly, outline=1, fill=1)\n",
    "        planes[idx] |= np.array(m, dtype=bool)\n",
    "\n",
    "    # pixels covered by >= 2 classes\n",
    "    overlap = planes.sum(axis=0) >= 2\n",
    "    return planes, overlap\n",
    "\n",
    "# Relevant directories and classes\n",
    "IMAGES_DIR = \"/Users/diegovelasco/Desktop/Diego/FING/DLFCV-FinalProject/data/dacl10k_v2_devphase/images/train\"\n",
    "ANNS_DIR   = \"/Users/diegovelasco/Desktop/Diego/FING/DLFCV-FinalProject/data_clean/annotations/train\"\n",
    "DEFECTS = ['Crack', 'ACrack', 'Wetspot', 'Efflorescence', 'Rust', 'Rockpocket', 'Hollowareas', 'Cavity', 'Spalling', 'Graffiti', 'Weathering', 'Restformwork', 'ExposedRebars']\n",
    "\n",
    "# Get annotations\n",
    "jsons = sorted(glob.glob(os.path.join(ANNS_DIR, \"*.json\")))\n",
    "n_imgs = 0\n",
    "n_overlap_imgs = 0\n",
    "overlap_pixels_total = 0\n",
    "\n",
    "# Compute overlaps\n",
    "for jp in tqdm(jsons, desc=\"Computing overlaps\", total=len(jsons)):\n",
    "    stem = os.path.splitext(os.path.basename(jp))[0]\n",
    "    ip = os.path.join(IMAGES_DIR, f\"{stem}.jpg\")\n",
    "    if not os.path.exists(ip):\n",
    "        continue\n",
    "    n_imgs += 1\n",
    "    _, ov = compute_overlap(ip, jp, DEFECTS)\n",
    "    n = int(ov.sum()) # number of overlapping pixels\n",
    "    if n > 0:\n",
    "        n_overlap_imgs += 1\n",
    "        overlap_pixels_total += n\n",
    "\n",
    "print(f\"Processed images: {n_imgs}\")\n",
    "print(f\"Images with overlaps: {n_overlap_imgs} ({100.0*n_overlap_imgs/max(1,n_imgs):.1f}%)\")\n",
    "print(f\"Total overlapping pixels: {overlap_pixels_total}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5239c5a",
   "metadata": {},
   "source": [
    "**Avg DACL10K image:** $1920×1440 ≈ 2.764.800$ pixels\n",
    "**Dataset size:** $ 6935$ images  \n",
    "**Total pixels:** $2.764.800 \\times 6935 = 19173888000$ pixels  \n",
    "\n",
    "**Ratio:** $915.524.988 / 19173888000 ≈ 0.0478 → ~4.8\\%$\n",
    "\n",
    "Because the dataset annotations are multilabel and overlap in ~5% of pixels, we collapse overlaps to a single class using a fixed priority hierarchy. This enables consistent multiclass training and evaluation for U-Net, SegFormer, and Mask2Former. A multilabel experiment will be explored separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "49c749ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Highest priority first (wins on overlap)\n",
    "PRIORITY = [\n",
    "    'Crack', 'ExposedRebars', 'Spalling', 'Rust', 'ACrack',\n",
    "    'Rockpocket', 'Hollowareas', 'Efflorescence', 'Cavity',\n",
    "    'Wetspot', 'Weathering', 'Restformwork', 'Graffiti',\n",
    "]\n",
    "\n",
    "PRIORITY_DICT = {cls: i+1 for i, cls in enumerate(PRIORITY)}  # 0 = background\n",
    "\n",
    "def rasterize_polygon_mask(w, h, pts):\n",
    "    m = Image.new('1', (w, h), 0)                   # 1-bit mask\n",
    "    ImageDraw.Draw(m).polygon([(float(x), float(y)) for x,y in pts],\n",
    "                              outline=1, fill=1)\n",
    "    return np.array(m, dtype=bool)\n",
    "\n",
    "def labelme_to_multiclass_png(json_path, out_png_path):\n",
    "    with open(json_path, 'r', encoding='utf-8') as f:\n",
    "        ann = json.load(f)\n",
    "\n",
    "    # image size\n",
    "    w, h = int(ann[\"imageWidth\"]), int(ann[\"imageHeight\"])\n",
    "\n",
    "    # per-class boolean planes (K,H,W)\n",
    "    planes = {cls: np.zeros((h, w), dtype=bool) for cls in PRIORITY}\n",
    "\n",
    "    # accumulate polygons into planes\n",
    "    for shp in ann.get(\"shapes\", []):\n",
    "        label = shp.get(\"label\", \"\")\n",
    "        pts = shp.get(\"points\", [])\n",
    "        if label in planes and len(pts) >= 3:\n",
    "            planes[label] |= rasterize_polygon_mask(w, h, pts)\n",
    "\n",
    "    # collapse to single-channel mask (uint8), background = 0\n",
    "    Y = np.zeros((h, w), dtype=np.uint8)\n",
    "    # iterate from LOWEST → HIGHEST so highest priority overwrites last\n",
    "    for cls in reversed(PRIORITY):\n",
    "        Y[planes[cls]] = PRIORITY_DICT[cls]\n",
    "\n",
    "    os.makedirs(os.path.dirname(out_png_path), exist_ok=True)\n",
    "    Image.fromarray(Y, mode='L').save(out_png_path)   # grayscale PNG\n",
    "\n",
    "def batch_convert_labelme_to_png(ann_dir, out_dir, pattern=\"*.json\"):\n",
    "    paths = sorted(glob.glob(os.path.join(ann_dir, pattern)))\n",
    "    for jp in tqdm(paths, desc=\"Converting to PNG\", total=len(paths)):\n",
    "        stem = os.path.splitext(os.path.basename(jp))[0]\n",
    "        outp = os.path.join(out_dir, f\"{stem}.png\")\n",
    "        labelme_to_multiclass_png(jp, outp)\n",
    "    print(f\"Done. Wrote {len(paths)} masks to: {out_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d698e1fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting to PNG: 100%|██████████| 6935/6935 [02:17<00:00, 50.27it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done. Wrote 6935 masks to: /Users/diegovelasco/Desktop/Diego/FING/DLFCV-FinalProject/data_clean/masks/train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleaning annotations: 100%|██████████| 975/975 [00:00<00:00, 2939.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done. Processed 975 files. Removed 0 shapes total.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "in_ann_dir = \"/Users/diegovelasco/Desktop/Diego/FING/DLFCV-FinalProject/data_clean/annotations/train\"\n",
    "out_mask_dir = \"/Users/diegovelasco/Desktop/Diego/FING/DLFCV-FinalProject/data_clean/masks/train\"\n",
    "batch_convert_labelme_to_png(in_ann_dir, out_mask_dir)\n",
    "\n",
    "# Validation\n",
    "in_ann_dir = \"/Users/diegovelasco/Desktop/Diego/FING/DLFCV-FinalProject/data_clean/annotations/validation\"\n",
    "out_ann_dir = \"/Users/diegovelasco/Desktop/Diego/FING/DLFCV-FinalProject/data_clean/masks/validation\"\n",
    "batch_clean_annotation(in_ann_dir, out_ann_dir, pattern)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
