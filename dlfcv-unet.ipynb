{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":13803291,"sourceType":"datasetVersion","datasetId":8788812},{"sourceId":13804249,"sourceType":"datasetVersion","datasetId":8789516}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Imports**","metadata":{}},{"cell_type":"code","source":"!pip install -q segmentation-models-pytorch torchmetrics transformers","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-21T13:36:40.991767Z","iopub.execute_input":"2025-11-21T13:36:40.992041Z","iopub.status.idle":"2025-11-21T13:36:44.314009Z","shell.execute_reply.started":"2025-11-21T13:36:40.992010Z","shell.execute_reply":"2025-11-21T13:36:44.313221Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"import json\nfrom pathlib import Path\n\nimport torch\nfrom torch import nn\nfrom torch.utils.data import DataLoader\n\nimport segmentation_models_pytorch as smp\nfrom torchmetrics import JaccardIndex, Accuracy, F1Score\nfrom torchmetrics.segmentation import DiceScore\nfrom torch.utils.data import Dataset\nfrom torchvision import transforms\nfrom torchvision.transforms import InterpolationMode\nfrom torch.amp import GradScaler, autocast\n\nfrom PIL import Image\nimport numpy as np\n\nfrom IPython.display import FileLink\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Device:\", device)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-21T13:46:42.200742Z","iopub.execute_input":"2025-11-21T13:46:42.201499Z","iopub.status.idle":"2025-11-21T13:46:42.207147Z","shell.execute_reply.started":"2025-11-21T13:46:42.201472Z","shell.execute_reply":"2025-11-21T13:46:42.206382Z"}},"outputs":[{"name":"stdout","text":"Device: cuda\n","output_type":"stream"}],"execution_count":22},{"cell_type":"markdown","source":"# **Setup**","metadata":{}},{"cell_type":"markdown","source":"## **Dataset**","metadata":{}},{"cell_type":"code","source":"# Initial setup\nDATA_ROOT = Path(\"/kaggle/input/data-clean\")\nIMG_DIR = DATA_ROOT / \"images\"\nMSK_DIR = DATA_ROOT / \"masks\"\n\ntrain_img_dir = IMG_DIR / \"train\"\nval_img_dir   = IMG_DIR / \"validation\"\ntest_img_dir  = IMG_DIR / \"test\"\n\ntrain_msk_dir = MSK_DIR / \"train\"\nval_msk_dir   = MSK_DIR / \"validation\"\ntest_msk_dir  = MSK_DIR / \"test\"\n\nCONFIG = {\n    \"experiment_name\": \"unet_resnet34_dacl10k_512\",\n    \"model\": \"Unet\",\n    \"encoder\": \"resnet34\",\n    \"encoder_weights\": \"imagenet\",\n    \"num_classes\": 14,\n    \"image_size\": (512, 512),\n    \"batch_size\": 8,\n    \"epochs\": 40,\n    \"learning_rate\": 1e-4,\n    \"loss\": \"CrossEntropyLoss\",\n    \"optimizer\": \"Adam\",\n    \"scheduler\": \"ReduceLROnPlateau\",\n    \"metrics\": [\n        \"mean_iou_per_class\",\n        \"dice_macro\",\n        \"f1_macro\",\n        \"global_pixel_accuracy\",\n    ],\n}\n\nNUM_CLASSES = CONFIG[\"num_classes\"]\nBATCH_SIZE  = CONFIG[\"batch_size\"]\nEPOCHS      = CONFIG[\"epochs\"]\nLR          = CONFIG[\"learning_rate\"]\nIMAGE_SIZE  = CONFIG[\"image_size\"]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-21T13:47:05.961077Z","iopub.execute_input":"2025-11-21T13:47:05.961813Z","iopub.status.idle":"2025-11-21T13:47:05.967128Z","shell.execute_reply.started":"2025-11-21T13:47:05.961780Z","shell.execute_reply":"2025-11-21T13:47:05.966388Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"# Dataset setup\nclass Dacl10kDataset(Dataset):\n    def __init__(self, img_dir, msk_dir, image_size=(512, 512)):\n        self.img_dir = Path(img_dir)\n        self.msk_dir = Path(msk_dir)\n        self.image_size = image_size\n\n        self.img_paths = sorted([p for p in self.img_dir.iterdir()])\n\n        # Transformations for training images\n        self.img_transform = transforms.Compose([\n            transforms.Resize(self.image_size, interpolation=transforms.InterpolationMode.BILINEAR),\n            transforms.ToTensor(),\n            transforms.Normalize(  # Normalize each channel with ImageNet normalization values\n                mean=[0.485, 0.456, 0.406],\n                std=[0.229, 0.224, 0.225],\n            ),\n        ])\n\n        self.mask_resize = transforms.Resize(\n            self.image_size,\n            interpolation=transforms.InterpolationMode.NEAREST, # Change interpolation value to keep integers\n        )\n\n    def __len__(self):\n        return len(self.img_paths)\n\n    def __getitem__(self, idx):\n        img_path = self.img_paths[idx]\n        msk_path = self.msk_dir / img_path.name.replace(\"jpg\", \"png\") # same filename, jpg -> png\n\n        # Image\n        img = Image.open(img_path).convert(\"RGB\")\n        img = self.img_transform(img)\n\n        # Mask\n        mask = Image.open(msk_path)\n        mask = self.mask_resize(mask)\n        mask = torch.from_numpy(np.array(mask, dtype=np.int64))  # [H, W] long with 0..13\n\n        return img, mask","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-21T13:47:08.101585Z","iopub.execute_input":"2025-11-21T13:47:08.102206Z","iopub.status.idle":"2025-11-21T13:47:08.108703Z","shell.execute_reply.started":"2025-11-21T13:47:08.102182Z","shell.execute_reply":"2025-11-21T13:47:08.107919Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"# Dataset definition\ntrain_dataset = Dacl10kDataset(train_img_dir, train_msk_dir, IMAGE_SIZE)\nval_dataset   = Dacl10kDataset(val_img_dir,   val_msk_dir,   IMAGE_SIZE)\n\ntrain_loader = DataLoader(\n    train_dataset,\n    batch_size=BATCH_SIZE,\n    shuffle=True,\n    num_workers=2,\n    pin_memory=True,\n)\n\nval_loader = DataLoader(\n    val_dataset,\n    batch_size=BATCH_SIZE,\n    shuffle=False,\n    num_workers=2,\n    pin_memory=True,\n)\n\nprint(\"Train samples:\", len(train_dataset), \" | batches:\", len(train_loader))\nprint(\"Val samples:  \", len(val_dataset),   \" | batches:\", len(val_loader))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-21T13:47:09.601100Z","iopub.execute_input":"2025-11-21T13:47:09.601415Z","iopub.status.idle":"2025-11-21T13:47:09.649193Z","shell.execute_reply.started":"2025-11-21T13:47:09.601390Z","shell.execute_reply":"2025-11-21T13:47:09.648520Z"}},"outputs":[{"name":"stdout","text":"Train samples: 5895  | batches: 737\nVal samples:   1040  | batches: 130\n","output_type":"stream"}],"execution_count":26},{"cell_type":"markdown","source":"## **Model, loss, optimizer, metrics**","metadata":{}},{"cell_type":"code","source":"# Model\nmodel = smp.Unet(\n    encoder_name=CONFIG[\"encoder\"],\n    encoder_weights=CONFIG[\"encoder_weights\"],\n    in_channels=3,\n    classes=NUM_CLASSES,\n).to(device)\n\n# Loss and optimizer. Scheduler will decrease learning rate as  it hits a plateau\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=LR)\nscheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n    optimizer,\n    mode=\"min\",\n    factor=0.5,\n    patience=3,\n    verbose=True,\n)\n\n# Metrics\n# 1) Mean IoU per class (Jaccard)\nmiou_metric = JaccardIndex(\n    task=\"multiclass\",\n    num_classes=NUM_CLASSES,\n).to(device)\n\n# 2) Dice score (macro over classes)\ndice_metric = DiceScore(\n    num_classes=NUM_CLASSES,\n    average=\"macro\",\n).to(device)\n\n# 3) F1 Score (macro over classes)\nf1_metric = F1Score(\n    task=\"multiclass\",\n    num_classes=NUM_CLASSES,\n    average=\"macro\",\n).to(device)\n\n# 4) Global Pixel Accuracy\nacc_metric = Accuracy(\n    task=\"multiclass\",\n    num_classes=NUM_CLASSES,\n).to(device)\n\nprint(\"UNet params (M):\", sum(p.numel() for p in model.parameters()) / 1e6)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-21T13:47:12.211041Z","iopub.execute_input":"2025-11-21T13:47:12.211355Z","iopub.status.idle":"2025-11-21T13:47:12.662562Z","shell.execute_reply.started":"2025-11-21T13:47:12.211305Z","shell.execute_reply":"2025-11-21T13:47:12.661738Z"}},"outputs":[{"name":"stdout","text":"UNet params (M): 24.438254\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"scaler = GradScaler(enabled=(device.type == \"cuda\")) # Uses AMP to speed up training\n\nCHECKPOINT_EVERY = 2  # epochs\n\ndef train_one_epoch(model, loader, optimizer, criterion, epoch):\n    model.train() # set model to training mode\n    running_loss = 0.0 # start total loss at 0.0\n\n    for step, (images, masks) in enumerate(loader, start=1):\n        images = images.to(device, non_blocking=True)\n        masks  = masks.to(device, non_blocking=True)\n\n        optimizer.zero_grad() # zero the gradients\n\n         # Uses AMP to speed up training\n        with autocast(device_type=\"cuda\", enabled=(device.type == \"cuda\")):\n            outputs = model(images)           \n            loss = criterion(outputs, masks)\n\n        scaler.scale(loss).backward()\n        scaler.step(optimizer)\n        scaler.update()\n\n        running_loss += loss.item() # add losses in each step\n\n        if step % 50 == 0 or step == 1:\n            print(f\"[Epoch {epoch}] Step {step}/{len(loader)} - Loss: {loss.item():.4f}\")\n\n    return running_loss / len(loader) # return mean loss across an epoch\n\n\n@torch.no_grad()\ndef evaluate(model, loader, criterion):\n    model.eval()\n    val_loss = 0.0\n\n    # Reset metrics each evaluation\n    miou_metric.reset()\n    dice_metric.reset()\n    f1_metric.reset()\n    acc_metric.reset()\n\n    for images, masks in loader:\n        images = images.to(device, non_blocking=True)\n        masks  = masks.to(device, non_blocking=True)\n\n        # Uses AMP to speed up training\n        with autocast(device_type=\"cuda\", enabled=(device.type == \"cuda\")):\n            outputs = model(images)\n            loss = criterion(outputs, masks)\n\n        val_loss += loss.item()\n\n        preds = torch.argmax(outputs, dim=1)  # Get class index with highest probability\n\n        # Update metrics \n        miou_metric.update(preds, masks)\n        dice_metric.update(preds, masks)\n        f1_metric.update(preds, masks)\n        acc_metric.update(preds, masks)\n\n    val_loss /= len(loader) # compute mean loss\n\n    miou = miou_metric.compute().item()   # mean IoU per class\n    dice = dice_metric.compute().item()   # macro Dice\n    mf1  = f1_metric.compute().item()     # macro F1\n    acc  = acc_metric.compute().item()    # global pixel accuracy\n\n    return val_loss, miou, dice, mf1, acc\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-21T13:47:14.087507Z","iopub.execute_input":"2025-11-21T13:47:14.087811Z","iopub.status.idle":"2025-11-21T13:47:14.096822Z","shell.execute_reply.started":"2025-11-21T13:47:14.087789Z","shell.execute_reply":"2025-11-21T13:47:14.096011Z"}},"outputs":[],"execution_count":28},{"cell_type":"markdown","source":"# **Train**","metadata":{}},{"cell_type":"code","source":"history = [] \nbest_miou = 0.0\n\nfor epoch in range(1, EPOCHS + 1):\n    print(f\"\\n===== Epoch {epoch}/{EPOCHS} =====\")\n\n    # Training epoch\n    train_loss = train_one_epoch(model, train_loader, optimizer, criterion, epoch)\n\n    # Metrics for train and validation sets\n    train_loss_eval, train_miou, train_dice, train_f1, train_acc = evaluate(model, train_loader, criterion)\n    val_loss, val_miou, val_dice, val_f1, val_acc = evaluate(model, val_loader, criterion)\n\n    # step scheduler on val_loss\n    scheduler.step(val_loss)\n\n    current_lr = optimizer.param_groups[0][\"lr\"]\n    \n    print(\n        f\"Epoch {epoch:03d} | \"\n        f\"TrainLoss(step): {train_loss:.4f} | \"\n        f\"TrainLoss(eval): {train_loss_eval:.4f} | \"\n        f\"ValLoss: {val_loss:.4f} | \"\n        f\"Train mIoU: {train_miou:.4f} | \"\n        f\"Val mIoU: {val_miou:.4f} | \"\n        f\"Val Dice: {val_dice:.4f} | \"\n        f\"Val F1: {val_f1:.4f} | \"\n        f\"Val Acc: {val_acc:.4f} | \"\n        f\"LR: {current_lr:.6f}\"\n    )\n\n    # Store metrics\n    history.append({\n        \"epoch\": epoch,\n        # training loss from the actual training loop\n        \"train_loss_step\": float(train_loss),\n        # training loss recomputed in eval mode (no dropout, BN in eval)\n        \"train_loss_eval\": float(train_loss_eval),\n        \"train_miou\": float(train_miou),\n        \"train_dice\": float(train_dice),\n        \"train_f1_macro\": float(train_f1),\n        \"train_global_pixel_accuracy\": float(train_acc),\n        \"val_loss\": float(val_loss),\n        \"val_miou\": float(val_miou),\n        \"val_dice\": float(val_dice),\n        \"val_f1_macro\": float(val_f1),\n        \"val_global_pixel_accuracy\": float(val_acc),\n        \"lr\": float(current_lr),\n    })\n\n    # save best model by mIoU\n    if val_miou > best_miou:\n        best_miou = val_miou\n        torch.save(model.state_dict(), \"unet_best_miou.pth\")\n        print(\"  -> New best mIoU; weights saved to unet_best_miou.pth\")\n\n    # periodic full checkpoint save\n    if epoch % CHECKPOINT_EVERY == 0:\n        ckpt_path = f\"unet_checkpoint_epoch_{epoch}.pth\"\n        torch.save({\n            \"config\": CONFIG,\n            \"epoch\": epoch,\n            \"model_state_dict\": model.state_dict(),\n            \"optimizer_state_dict\": optimizer.state_dict(),\n            \"scheduler_state_dict\": scheduler.state_dict(),\n            \"best_miou\": best_miou,\n            \"history\": history,\n        }, ckpt_path)\n        print(f\"  -> Checkpoint saved to {ckpt_path}\")\n\n# final \"last\" checkpoint\ntorch.save({\n    \"config\": CONFIG,\n    \"epoch\": EPOCHS,\n    \"model_state_dict\": model.state_dict(),\n    \"optimizer_state_dict\": optimizer.state_dict(),\n    \"scheduler_state_dict\": scheduler.state_dict(),\n    \"best_miou\": best_miou,\n    \"history\": history,\n}, \"unet_last.pth\")\n\nprint(\"\\nTraining complete. Best mIoU:\", best_miou)\n\n# Store training logs in JSON format\n\noutput_path = Path(\"/kaggle/working/unet_results.json\")\n\nresults = {\n    \"config\": CONFIG,\n    \"history\": history,\n}\n\nwith open(output_path, \"w\") as f:\n    json.dump(results, f, indent=2)\n\nprint(\"Saved metrics to:\", output_path)\n\n# Download link for results\nFileLink('/kaggle/working/unet_results.json')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-21T14:08:40.675740Z","iopub.execute_input":"2025-11-21T14:08:40.676480Z","iopub.status.idle":"2025-11-21T20:07:37.035039Z","shell.execute_reply.started":"2025-11-21T14:08:40.676450Z","shell.execute_reply":"2025-11-21T20:07:37.034096Z"}},"outputs":[{"name":"stdout","text":"\n===== Epoch 1/40 =====\n[Epoch 1] Step 1/737 - Loss: 0.8133\n[Epoch 1] Step 50/737 - Loss: 0.8753\n[Epoch 1] Step 100/737 - Loss: 0.4947\n[Epoch 1] Step 150/737 - Loss: 1.0082\n[Epoch 1] Step 200/737 - Loss: 0.8362\n[Epoch 1] Step 250/737 - Loss: 0.8627\n[Epoch 1] Step 300/737 - Loss: 0.6260\n[Epoch 1] Step 350/737 - Loss: 0.4254\n[Epoch 1] Step 400/737 - Loss: 0.4679\n[Epoch 1] Step 450/737 - Loss: 0.7867\n[Epoch 1] Step 500/737 - Loss: 0.9071\n[Epoch 1] Step 550/737 - Loss: 0.7628\n[Epoch 1] Step 600/737 - Loss: 0.8683\n[Epoch 1] Step 650/737 - Loss: 0.7622\n[Epoch 1] Step 700/737 - Loss: 0.6173\nEpoch 001 | TrainLoss(step): 0.8307 | TrainLoss(eval): 0.7277 | ValLoss: 0.8137 | Train mIoU: 0.1415 | Val mIoU: 0.1265 | Val Dice: 1.3896 | Val F1: 0.1755 | Val Acc: 0.7672 | LR: 0.000100\n  -> New best mIoU; weights saved to unet_best_miou.pth\n\n===== Epoch 2/40 =====\n[Epoch 2] Step 1/737 - Loss: 1.2544\n[Epoch 2] Step 50/737 - Loss: 1.0275\n[Epoch 2] Step 100/737 - Loss: 0.7002\n[Epoch 2] Step 150/737 - Loss: 0.9886\n[Epoch 2] Step 200/737 - Loss: 0.8030\n[Epoch 2] Step 250/737 - Loss: 0.8756\n[Epoch 2] Step 300/737 - Loss: 0.7528\n[Epoch 2] Step 350/737 - Loss: 0.9531\n[Epoch 2] Step 400/737 - Loss: 0.7679\n[Epoch 2] Step 450/737 - Loss: 0.9672\n[Epoch 2] Step 500/737 - Loss: 0.7020\n[Epoch 2] Step 550/737 - Loss: 0.9761\n[Epoch 2] Step 600/737 - Loss: 0.9925\n[Epoch 2] Step 650/737 - Loss: 1.2168\n[Epoch 2] Step 700/737 - Loss: 1.2088\nEpoch 002 | TrainLoss(step): 0.7816 | TrainLoss(eval): 0.6936 | ValLoss: 0.8126 | Train mIoU: 0.1655 | Val mIoU: 0.1436 | Val Dice: 1.1645 | Val F1: 0.1998 | Val Acc: 0.7662 | LR: 0.000100\n  -> New best mIoU; weights saved to unet_best_miou.pth\n  -> Checkpoint saved to unet_checkpoint_epoch_2.pth\n\n===== Epoch 3/40 =====\n[Epoch 3] Step 1/737 - Loss: 0.9424\n[Epoch 3] Step 50/737 - Loss: 0.6064\n[Epoch 3] Step 100/737 - Loss: 0.8401\n[Epoch 3] Step 150/737 - Loss: 0.5388\n[Epoch 3] Step 200/737 - Loss: 0.6367\n[Epoch 3] Step 250/737 - Loss: 0.7205\n[Epoch 3] Step 300/737 - Loss: 1.2317\n[Epoch 3] Step 350/737 - Loss: 0.5214\n[Epoch 3] Step 400/737 - Loss: 0.4266\n[Epoch 3] Step 450/737 - Loss: 0.7034\n[Epoch 3] Step 500/737 - Loss: 0.8281\n[Epoch 3] Step 550/737 - Loss: 0.5013\n[Epoch 3] Step 600/737 - Loss: 0.5512\n[Epoch 3] Step 650/737 - Loss: 0.5085\n[Epoch 3] Step 700/737 - Loss: 0.8790\nEpoch 003 | TrainLoss(step): 0.7335 | TrainLoss(eval): 0.6401 | ValLoss: 0.7691 | Train mIoU: 0.1915 | Val mIoU: 0.1525 | Val Dice: 1.2919 | Val F1: 0.2100 | Val Acc: 0.7673 | LR: 0.000100\n  -> New best mIoU; weights saved to unet_best_miou.pth\n\n===== Epoch 4/40 =====\n[Epoch 4] Step 1/737 - Loss: 0.7286\n[Epoch 4] Step 50/737 - Loss: 0.5034\n[Epoch 4] Step 100/737 - Loss: 0.7686\n[Epoch 4] Step 150/737 - Loss: 1.0606\n[Epoch 4] Step 200/737 - Loss: 0.5337\n[Epoch 4] Step 250/737 - Loss: 0.4237\n[Epoch 4] Step 300/737 - Loss: 0.5831\n[Epoch 4] Step 350/737 - Loss: 0.7696\n[Epoch 4] Step 400/737 - Loss: 0.8943\n[Epoch 4] Step 450/737 - Loss: 0.9660\n[Epoch 4] Step 500/737 - Loss: 0.6225\n[Epoch 4] Step 550/737 - Loss: 0.3992\n[Epoch 4] Step 600/737 - Loss: 0.6081\n[Epoch 4] Step 650/737 - Loss: 0.6863\n[Epoch 4] Step 700/737 - Loss: 1.2317\nEpoch 004 | TrainLoss(step): 0.6819 | TrainLoss(eval): 0.5898 | ValLoss: 0.7767 | Train mIoU: 0.2213 | Val mIoU: 0.1661 | Val Dice: 2.0027 | Val F1: 0.2293 | Val Acc: 0.7702 | LR: 0.000100\n  -> New best mIoU; weights saved to unet_best_miou.pth\n  -> Checkpoint saved to unet_checkpoint_epoch_4.pth\n\n===== Epoch 5/40 =====\n[Epoch 5] Step 1/737 - Loss: 1.0661\n[Epoch 5] Step 50/737 - Loss: 0.6571\n[Epoch 5] Step 100/737 - Loss: 0.4809\n[Epoch 5] Step 150/737 - Loss: 0.5619\n[Epoch 5] Step 200/737 - Loss: 0.3436\n[Epoch 5] Step 250/737 - Loss: 0.7365\n[Epoch 5] Step 300/737 - Loss: 0.9103\n[Epoch 5] Step 350/737 - Loss: 0.4570\n[Epoch 5] Step 400/737 - Loss: 0.6663\n[Epoch 5] Step 450/737 - Loss: 0.9234\n[Epoch 5] Step 500/737 - Loss: 0.4283\n[Epoch 5] Step 550/737 - Loss: 0.4613\n[Epoch 5] Step 600/737 - Loss: 0.6049\n[Epoch 5] Step 650/737 - Loss: 0.7950\n[Epoch 5] Step 700/737 - Loss: 0.5977\nEpoch 005 | TrainLoss(step): 0.6300 | TrainLoss(eval): 0.5258 | ValLoss: 0.7701 | Train mIoU: 0.2313 | Val mIoU: 0.1609 | Val Dice: 1.9767 | Val F1: 0.2254 | Val Acc: 0.7664 | LR: 0.000100\n\n===== Epoch 6/40 =====\n[Epoch 6] Step 1/737 - Loss: 0.8473\n[Epoch 6] Step 50/737 - Loss: 0.6099\n[Epoch 6] Step 100/737 - Loss: 0.4844\n[Epoch 6] Step 150/737 - Loss: 0.5000\n[Epoch 6] Step 200/737 - Loss: 0.5759\n[Epoch 6] Step 250/737 - Loss: 0.6259\n[Epoch 6] Step 300/737 - Loss: 0.3721\n[Epoch 6] Step 350/737 - Loss: 0.5555\n[Epoch 6] Step 400/737 - Loss: 0.5606\n[Epoch 6] Step 450/737 - Loss: 0.6715\n[Epoch 6] Step 500/737 - Loss: 0.4306\n[Epoch 6] Step 550/737 - Loss: 0.6539\n[Epoch 6] Step 600/737 - Loss: 0.3117\n[Epoch 6] Step 650/737 - Loss: 0.5364\n[Epoch 6] Step 700/737 - Loss: 0.4630\nEpoch 006 | TrainLoss(step): 0.5725 | TrainLoss(eval): 0.4552 | ValLoss: 0.7616 | Train mIoU: 0.2977 | Val mIoU: 0.2052 | Val Dice: 2.0564 | Val F1: 0.2855 | Val Acc: 0.7854 | LR: 0.000100\n  -> New best mIoU; weights saved to unet_best_miou.pth\n  -> Checkpoint saved to unet_checkpoint_epoch_6.pth\n\n===== Epoch 7/40 =====\n[Epoch 7] Step 1/737 - Loss: 1.0062\n[Epoch 7] Step 50/737 - Loss: 0.9971\n[Epoch 7] Step 100/737 - Loss: 0.5091\n[Epoch 7] Step 150/737 - Loss: 0.4689\n[Epoch 7] Step 200/737 - Loss: 0.3882\n[Epoch 7] Step 250/737 - Loss: 0.5207\n[Epoch 7] Step 300/737 - Loss: 0.3986\n[Epoch 7] Step 350/737 - Loss: 0.4582\n[Epoch 7] Step 400/737 - Loss: 0.6048\n[Epoch 7] Step 450/737 - Loss: 0.5495\n[Epoch 7] Step 500/737 - Loss: 0.3909\n[Epoch 7] Step 550/737 - Loss: 0.4379\n[Epoch 7] Step 600/737 - Loss: 0.3661\n[Epoch 7] Step 650/737 - Loss: 0.3320\n[Epoch 7] Step 700/737 - Loss: 0.6352\nEpoch 007 | TrainLoss(step): 0.5170 | TrainLoss(eval): 0.4086 | ValLoss: 0.7647 | Train mIoU: 0.3416 | Val mIoU: 0.2212 | Val Dice: 2.5488 | Val F1: 0.3108 | Val Acc: 0.7764 | LR: 0.000100\n  -> New best mIoU; weights saved to unet_best_miou.pth\n\n===== Epoch 8/40 =====\n[Epoch 8] Step 1/737 - Loss: 0.3385\n[Epoch 8] Step 50/737 - Loss: 0.7307\n[Epoch 8] Step 100/737 - Loss: 0.5121\n[Epoch 8] Step 150/737 - Loss: 0.4061\n[Epoch 8] Step 200/737 - Loss: 0.5430\n[Epoch 8] Step 250/737 - Loss: 0.4350\n[Epoch 8] Step 300/737 - Loss: 0.4846\n[Epoch 8] Step 350/737 - Loss: 0.6185\n[Epoch 8] Step 400/737 - Loss: 0.2232\n[Epoch 8] Step 450/737 - Loss: 0.4612\n[Epoch 8] Step 500/737 - Loss: 0.4357\n[Epoch 8] Step 550/737 - Loss: 0.4128\n[Epoch 8] Step 600/737 - Loss: 0.3131\n[Epoch 8] Step 650/737 - Loss: 0.4187\n[Epoch 8] Step 700/737 - Loss: 0.5237\nEpoch 008 | TrainLoss(step): 0.4711 | TrainLoss(eval): 0.4045 | ValLoss: 0.8009 | Train mIoU: 0.3447 | Val mIoU: 0.2169 | Val Dice: 2.6212 | Val F1: 0.3074 | Val Acc: 0.7588 | LR: 0.000100\n  -> Checkpoint saved to unet_checkpoint_epoch_8.pth\n\n===== Epoch 9/40 =====\n[Epoch 9] Step 1/737 - Loss: 0.3746\n[Epoch 9] Step 50/737 - Loss: 0.2768\n[Epoch 9] Step 100/737 - Loss: 0.4769\n[Epoch 9] Step 150/737 - Loss: 0.4816\n[Epoch 9] Step 200/737 - Loss: 0.5143\n[Epoch 9] Step 250/737 - Loss: 0.2966\n[Epoch 9] Step 300/737 - Loss: 0.2735\n[Epoch 9] Step 350/737 - Loss: 0.8042\n[Epoch 9] Step 400/737 - Loss: 0.2117\n[Epoch 9] Step 450/737 - Loss: 0.3550\n[Epoch 9] Step 500/737 - Loss: 0.3249\n[Epoch 9] Step 550/737 - Loss: 0.3819\n[Epoch 9] Step 600/737 - Loss: 0.5661\n[Epoch 9] Step 650/737 - Loss: 0.6453\n[Epoch 9] Step 700/737 - Loss: 0.3995\nEpoch 009 | TrainLoss(step): 0.4212 | TrainLoss(eval): 0.3331 | ValLoss: 0.8563 | Train mIoU: 0.3862 | Val mIoU: 0.2283 | Val Dice: 2.3783 | Val F1: 0.3203 | Val Acc: 0.7779 | LR: 0.000100\n  -> New best mIoU; weights saved to unet_best_miou.pth\n\n===== Epoch 10/40 =====\n[Epoch 10] Step 1/737 - Loss: 0.3406\n[Epoch 10] Step 50/737 - Loss: 0.3891\n[Epoch 10] Step 100/737 - Loss: 0.4313\n[Epoch 10] Step 150/737 - Loss: 0.3796\n[Epoch 10] Step 200/737 - Loss: 0.2441\n[Epoch 10] Step 250/737 - Loss: 0.4393\n[Epoch 10] Step 300/737 - Loss: 0.3592\n[Epoch 10] Step 350/737 - Loss: 0.2346\n[Epoch 10] Step 400/737 - Loss: 0.2934\n[Epoch 10] Step 450/737 - Loss: 0.3545\n[Epoch 10] Step 500/737 - Loss: 0.3659\n[Epoch 10] Step 550/737 - Loss: 0.4150\n[Epoch 10] Step 600/737 - Loss: 0.3736\n[Epoch 10] Step 650/737 - Loss: 0.5612\n[Epoch 10] Step 700/737 - Loss: 0.3585\nEpoch 010 | TrainLoss(step): 0.3868 | TrainLoss(eval): 0.3150 | ValLoss: 0.8509 | Train mIoU: 0.3957 | Val mIoU: 0.2228 | Val Dice: 2.4393 | Val F1: 0.3131 | Val Acc: 0.7850 | LR: 0.000050\n  -> Checkpoint saved to unet_checkpoint_epoch_10.pth\n\n===== Epoch 11/40 =====\n[Epoch 11] Step 1/737 - Loss: 0.3241\n[Epoch 11] Step 50/737 - Loss: 0.3734\n[Epoch 11] Step 100/737 - Loss: 0.1943\n[Epoch 11] Step 150/737 - Loss: 0.2436\n[Epoch 11] Step 200/737 - Loss: 0.2636\n[Epoch 11] Step 250/737 - Loss: 0.2845\n[Epoch 11] Step 300/737 - Loss: 0.2923\n[Epoch 11] Step 350/737 - Loss: 0.2964\n[Epoch 11] Step 400/737 - Loss: 0.2969\n[Epoch 11] Step 450/737 - Loss: 0.2694\n[Epoch 11] Step 500/737 - Loss: 0.3802\n[Epoch 11] Step 550/737 - Loss: 0.1737\n[Epoch 11] Step 600/737 - Loss: 0.2966\n[Epoch 11] Step 650/737 - Loss: 0.3793\n[Epoch 11] Step 700/737 - Loss: 0.2128\nEpoch 011 | TrainLoss(step): 0.3203 | TrainLoss(eval): 0.2519 | ValLoss: 0.8265 | Train mIoU: 0.4819 | Val mIoU: 0.2493 | Val Dice: 2.4498 | Val F1: 0.3529 | Val Acc: 0.7878 | LR: 0.000050\n  -> New best mIoU; weights saved to unet_best_miou.pth\n\n===== Epoch 12/40 =====\n[Epoch 12] Step 1/737 - Loss: 0.3118\n[Epoch 12] Step 50/737 - Loss: 0.2861\n[Epoch 12] Step 100/737 - Loss: 0.2957\n[Epoch 12] Step 150/737 - Loss: 0.2942\n[Epoch 12] Step 200/737 - Loss: 0.5312\n[Epoch 12] Step 250/737 - Loss: 0.3270\n[Epoch 12] Step 300/737 - Loss: 0.2661\n[Epoch 12] Step 350/737 - Loss: 0.3583\n[Epoch 12] Step 400/737 - Loss: 0.2821\n[Epoch 12] Step 450/737 - Loss: 0.2912\n[Epoch 12] Step 500/737 - Loss: 0.1609\n[Epoch 12] Step 550/737 - Loss: 0.4430\n[Epoch 12] Step 600/737 - Loss: 0.2426\n[Epoch 12] Step 650/737 - Loss: 0.2442\n[Epoch 12] Step 700/737 - Loss: 0.3505\nEpoch 012 | TrainLoss(step): 0.2854 | TrainLoss(eval): 0.2344 | ValLoss: 0.8609 | Train mIoU: 0.4996 | Val mIoU: 0.2441 | Val Dice: 2.4850 | Val F1: 0.3456 | Val Acc: 0.7865 | LR: 0.000050\n  -> Checkpoint saved to unet_checkpoint_epoch_12.pth\n\n===== Epoch 13/40 =====\n[Epoch 13] Step 1/737 - Loss: 0.2512\n[Epoch 13] Step 50/737 - Loss: 0.3193\n[Epoch 13] Step 100/737 - Loss: 0.2259\n[Epoch 13] Step 150/737 - Loss: 0.2121\n[Epoch 13] Step 200/737 - Loss: 0.2234\n[Epoch 13] Step 250/737 - Loss: 0.2381\n[Epoch 13] Step 300/737 - Loss: 0.1687\n[Epoch 13] Step 350/737 - Loss: 0.3052\n[Epoch 13] Step 400/737 - Loss: 0.1585\n[Epoch 13] Step 450/737 - Loss: 0.2412\n[Epoch 13] Step 500/737 - Loss: 0.1809\n[Epoch 13] Step 550/737 - Loss: 0.2333\n[Epoch 13] Step 600/737 - Loss: 0.1926\n[Epoch 13] Step 650/737 - Loss: 0.1657\n[Epoch 13] Step 700/737 - Loss: 0.1829\nEpoch 013 | TrainLoss(step): 0.2649 | TrainLoss(eval): 0.2143 | ValLoss: 0.8614 | Train mIoU: 0.5195 | Val mIoU: 0.2386 | Val Dice: 2.4380 | Val F1: 0.3368 | Val Acc: 0.7891 | LR: 0.000050\n\n===== Epoch 14/40 =====\n[Epoch 14] Step 1/737 - Loss: 0.2576\n[Epoch 14] Step 50/737 - Loss: 0.2365\n[Epoch 14] Step 100/737 - Loss: 0.2687\n[Epoch 14] Step 150/737 - Loss: 0.1986\n[Epoch 14] Step 200/737 - Loss: 0.2195\n[Epoch 14] Step 250/737 - Loss: 0.2499\n[Epoch 14] Step 300/737 - Loss: 0.1898\n[Epoch 14] Step 350/737 - Loss: 0.3496\n[Epoch 14] Step 400/737 - Loss: 0.2513\n[Epoch 14] Step 450/737 - Loss: 0.2428\n[Epoch 14] Step 500/737 - Loss: 0.2908\n[Epoch 14] Step 550/737 - Loss: 0.1319\n[Epoch 14] Step 600/737 - Loss: 0.2414\n[Epoch 14] Step 650/737 - Loss: 0.3453\n[Epoch 14] Step 700/737 - Loss: 0.1911\nEpoch 014 | TrainLoss(step): 0.2415 | TrainLoss(eval): 0.2005 | ValLoss: 0.9015 | Train mIoU: 0.5298 | Val mIoU: 0.2367 | Val Dice: 2.4322 | Val F1: 0.3365 | Val Acc: 0.7838 | LR: 0.000025\n  -> Checkpoint saved to unet_checkpoint_epoch_14.pth\n\n===== Epoch 15/40 =====\n[Epoch 15] Step 1/737 - Loss: 0.3855\n[Epoch 15] Step 50/737 - Loss: 0.1148\n[Epoch 15] Step 100/737 - Loss: 0.1046\n[Epoch 15] Step 150/737 - Loss: 0.2254\n[Epoch 15] Step 200/737 - Loss: 0.2632\n[Epoch 15] Step 250/737 - Loss: 0.1882\n[Epoch 15] Step 300/737 - Loss: 0.2386\n[Epoch 15] Step 350/737 - Loss: 0.1733\n[Epoch 15] Step 400/737 - Loss: 0.1575\n[Epoch 15] Step 450/737 - Loss: 0.3678\n[Epoch 15] Step 500/737 - Loss: 0.1960\n[Epoch 15] Step 550/737 - Loss: 0.2576\n[Epoch 15] Step 600/737 - Loss: 0.1310\n[Epoch 15] Step 650/737 - Loss: 0.2666\n[Epoch 15] Step 700/737 - Loss: 0.1358\nEpoch 015 | TrainLoss(step): 0.2145 | TrainLoss(eval): 0.1806 | ValLoss: 0.9091 | Train mIoU: 0.5465 | Val mIoU: 0.2508 | Val Dice: 2.5223 | Val F1: 0.3529 | Val Acc: 0.7894 | LR: 0.000025\n  -> New best mIoU; weights saved to unet_best_miou.pth\n\n===== Epoch 16/40 =====\n[Epoch 16] Step 1/737 - Loss: 0.3183\n[Epoch 16] Step 50/737 - Loss: 0.1908\n[Epoch 16] Step 100/737 - Loss: 0.2364\n[Epoch 16] Step 150/737 - Loss: 0.1437\n[Epoch 16] Step 200/737 - Loss: 0.0997\n[Epoch 16] Step 250/737 - Loss: 0.1245\n[Epoch 16] Step 300/737 - Loss: 0.4496\n[Epoch 16] Step 350/737 - Loss: 0.4041\n[Epoch 16] Step 400/737 - Loss: 0.1562\n[Epoch 16] Step 450/737 - Loss: 0.2069\n[Epoch 16] Step 500/737 - Loss: 0.1225\n[Epoch 16] Step 550/737 - Loss: 0.1222\n[Epoch 16] Step 600/737 - Loss: 0.1637\n[Epoch 16] Step 650/737 - Loss: 0.1406\n[Epoch 16] Step 700/737 - Loss: 0.1501\nEpoch 016 | TrainLoss(step): 0.2004 | TrainLoss(eval): 0.1741 | ValLoss: 0.9176 | Train mIoU: 0.5481 | Val mIoU: 0.2415 | Val Dice: 2.4267 | Val F1: 0.3434 | Val Acc: 0.7890 | LR: 0.000025\n  -> Checkpoint saved to unet_checkpoint_epoch_16.pth\n\n===== Epoch 17/40 =====\n[Epoch 17] Step 1/737 - Loss: 0.1487\n[Epoch 17] Step 50/737 - Loss: 0.2091\n[Epoch 17] Step 100/737 - Loss: 0.1212\n[Epoch 17] Step 150/737 - Loss: 0.0980\n[Epoch 17] Step 200/737 - Loss: 0.2108\n[Epoch 17] Step 250/737 - Loss: 0.3355\n[Epoch 17] Step 300/737 - Loss: 0.1958\n[Epoch 17] Step 350/737 - Loss: 0.1692\n[Epoch 17] Step 400/737 - Loss: 0.1358\n[Epoch 17] Step 450/737 - Loss: 0.1788\n[Epoch 17] Step 500/737 - Loss: 0.1577\n[Epoch 17] Step 550/737 - Loss: 0.2195\n[Epoch 17] Step 600/737 - Loss: 0.1724\n[Epoch 17] Step 650/737 - Loss: 0.2052\n[Epoch 17] Step 700/737 - Loss: 0.1111\nEpoch 017 | TrainLoss(step): 0.1886 | TrainLoss(eval): 0.1614 | ValLoss: 0.9385 | Train mIoU: 0.5619 | Val mIoU: 0.2443 | Val Dice: 2.4734 | Val F1: 0.3465 | Val Acc: 0.7868 | LR: 0.000025\n\n===== Epoch 18/40 =====\n[Epoch 18] Step 1/737 - Loss: 0.1231\n[Epoch 18] Step 50/737 - Loss: 0.1421\n[Epoch 18] Step 100/737 - Loss: 0.2296\n[Epoch 18] Step 150/737 - Loss: 0.1216\n[Epoch 18] Step 200/737 - Loss: 0.1459\n[Epoch 18] Step 250/737 - Loss: 0.2023\n[Epoch 18] Step 300/737 - Loss: 0.1431\n[Epoch 18] Step 350/737 - Loss: 0.1313\n[Epoch 18] Step 400/737 - Loss: 0.2032\n[Epoch 18] Step 450/737 - Loss: 0.1080\n[Epoch 18] Step 500/737 - Loss: 0.1055\n[Epoch 18] Step 550/737 - Loss: 0.2557\n[Epoch 18] Step 600/737 - Loss: 0.2239\n[Epoch 18] Step 650/737 - Loss: 0.2726\n[Epoch 18] Step 700/737 - Loss: 0.1990\nEpoch 018 | TrainLoss(step): 0.1794 | TrainLoss(eval): 0.1556 | ValLoss: 1.0226 | Train mIoU: 0.5655 | Val mIoU: 0.2393 | Val Dice: 2.3473 | Val F1: 0.3390 | Val Acc: 0.7891 | LR: 0.000013\n  -> Checkpoint saved to unet_checkpoint_epoch_18.pth\n\n===== Epoch 19/40 =====\n[Epoch 19] Step 1/737 - Loss: 0.3315\n[Epoch 19] Step 50/737 - Loss: 0.2156\n[Epoch 19] Step 100/737 - Loss: 0.0966\n[Epoch 19] Step 150/737 - Loss: 0.1822\n[Epoch 19] Step 200/737 - Loss: 0.2463\n[Epoch 19] Step 250/737 - Loss: 0.1856\n[Epoch 19] Step 300/737 - Loss: 0.2024\n[Epoch 19] Step 350/737 - Loss: 0.3047\n[Epoch 19] Step 400/737 - Loss: 0.1599\n[Epoch 19] Step 450/737 - Loss: 0.1333\n[Epoch 19] Step 500/737 - Loss: 0.0698\n[Epoch 19] Step 550/737 - Loss: 0.1543\n[Epoch 19] Step 600/737 - Loss: 0.1561\n[Epoch 19] Step 650/737 - Loss: 0.2149\n[Epoch 19] Step 700/737 - Loss: 0.1257\nEpoch 019 | TrainLoss(step): 0.1679 | TrainLoss(eval): 0.1447 | ValLoss: 0.9616 | Train mIoU: 0.5742 | Val mIoU: 0.2464 | Val Dice: 2.5597 | Val F1: 0.3479 | Val Acc: 0.7870 | LR: 0.000013\n\n===== Epoch 20/40 =====\n[Epoch 20] Step 1/737 - Loss: 0.1241\n[Epoch 20] Step 50/737 - Loss: 0.2372\n[Epoch 20] Step 100/737 - Loss: 0.1726\n[Epoch 20] Step 150/737 - Loss: 0.2170\n[Epoch 20] Step 200/737 - Loss: 0.2457\n[Epoch 20] Step 250/737 - Loss: 0.1713\n[Epoch 20] Step 300/737 - Loss: 0.1550\n[Epoch 20] Step 350/737 - Loss: 0.2841\n[Epoch 20] Step 400/737 - Loss: 0.2260\n[Epoch 20] Step 450/737 - Loss: 0.1252\n[Epoch 20] Step 500/737 - Loss: 0.1150\n[Epoch 20] Step 550/737 - Loss: 0.1879\n[Epoch 20] Step 600/737 - Loss: 0.1420\n[Epoch 20] Step 650/737 - Loss: 0.1391\n[Epoch 20] Step 700/737 - Loss: 0.1397\nEpoch 020 | TrainLoss(step): 0.1601 | TrainLoss(eval): 0.1409 | ValLoss: 0.9718 | Train mIoU: 0.5779 | Val mIoU: 0.2458 | Val Dice: 2.4729 | Val F1: 0.3473 | Val Acc: 0.7867 | LR: 0.000013\n  -> Checkpoint saved to unet_checkpoint_epoch_20.pth\n\n===== Epoch 21/40 =====\n[Epoch 21] Step 1/737 - Loss: 0.2346\n[Epoch 21] Step 50/737 - Loss: 0.1411\n[Epoch 21] Step 100/737 - Loss: 0.2342\n[Epoch 21] Step 150/737 - Loss: 0.1467\n[Epoch 21] Step 200/737 - Loss: 0.1442\n[Epoch 21] Step 250/737 - Loss: 0.1977\n[Epoch 21] Step 300/737 - Loss: 0.1973\n[Epoch 21] Step 350/737 - Loss: 0.0707\n[Epoch 21] Step 400/737 - Loss: 0.1120\n[Epoch 21] Step 450/737 - Loss: 0.2224\n[Epoch 21] Step 500/737 - Loss: 0.1630\n[Epoch 21] Step 550/737 - Loss: 0.1928\n[Epoch 21] Step 600/737 - Loss: 0.2391\n[Epoch 21] Step 650/737 - Loss: 0.1178\n[Epoch 21] Step 700/737 - Loss: 0.1320\nEpoch 021 | TrainLoss(step): 0.1553 | TrainLoss(eval): 0.1436 | ValLoss: 1.0209 | Train mIoU: 0.5795 | Val mIoU: 0.2423 | Val Dice: 2.4475 | Val F1: 0.3435 | Val Acc: 0.7873 | LR: 0.000013\n\n===== Epoch 22/40 =====\n[Epoch 22] Step 1/737 - Loss: 0.1826\n[Epoch 22] Step 50/737 - Loss: 0.0908\n[Epoch 22] Step 100/737 - Loss: 0.1650\n[Epoch 22] Step 150/737 - Loss: 0.1118\n[Epoch 22] Step 200/737 - Loss: 0.1519\n[Epoch 22] Step 250/737 - Loss: 0.0809\n[Epoch 22] Step 300/737 - Loss: 0.1323\n[Epoch 22] Step 350/737 - Loss: 0.1250\n[Epoch 22] Step 400/737 - Loss: 0.1432\n[Epoch 22] Step 450/737 - Loss: 0.1929\n[Epoch 22] Step 500/737 - Loss: 0.2099\n[Epoch 22] Step 550/737 - Loss: 0.0523\n[Epoch 22] Step 600/737 - Loss: 0.0854\n[Epoch 22] Step 650/737 - Loss: 0.1274\n[Epoch 22] Step 700/737 - Loss: 0.0856\nEpoch 022 | TrainLoss(step): 0.1502 | TrainLoss(eval): 0.1345 | ValLoss: 1.0187 | Train mIoU: 0.5957 | Val mIoU: 0.2466 | Val Dice: 2.4826 | Val F1: 0.3523 | Val Acc: 0.7832 | LR: 0.000006\n  -> Checkpoint saved to unet_checkpoint_epoch_22.pth\n\n===== Epoch 23/40 =====\n[Epoch 23] Step 1/737 - Loss: 0.1275\n[Epoch 23] Step 50/737 - Loss: 0.0923\n[Epoch 23] Step 100/737 - Loss: 0.1459\n[Epoch 23] Step 150/737 - Loss: 0.1801\n[Epoch 23] Step 200/737 - Loss: 0.1234\n[Epoch 23] Step 250/737 - Loss: 0.0918\n[Epoch 23] Step 300/737 - Loss: 0.1543\n[Epoch 23] Step 350/737 - Loss: 0.2272\n[Epoch 23] Step 400/737 - Loss: 0.1573\n[Epoch 23] Step 450/737 - Loss: 0.1426\n[Epoch 23] Step 500/737 - Loss: 0.1316\n[Epoch 23] Step 550/737 - Loss: 0.0787\n[Epoch 23] Step 600/737 - Loss: 0.0513\n[Epoch 23] Step 650/737 - Loss: 0.1385\n[Epoch 23] Step 700/737 - Loss: 0.1634\nEpoch 023 | TrainLoss(step): 0.1452 | TrainLoss(eval): 0.1316 | ValLoss: 1.0393 | Train mIoU: 0.6041 | Val mIoU: 0.2432 | Val Dice: 2.3914 | Val F1: 0.3484 | Val Acc: 0.7864 | LR: 0.000006\n\n===== Epoch 24/40 =====\n[Epoch 24] Step 1/737 - Loss: 0.0989\n[Epoch 24] Step 50/737 - Loss: 0.1379\n[Epoch 24] Step 100/737 - Loss: 0.1603\n[Epoch 24] Step 150/737 - Loss: 0.1237\n[Epoch 24] Step 200/737 - Loss: 0.1732\n[Epoch 24] Step 250/737 - Loss: 0.1735\n[Epoch 24] Step 300/737 - Loss: 0.0950\n[Epoch 24] Step 350/737 - Loss: 0.1553\n[Epoch 24] Step 400/737 - Loss: 0.1204\n[Epoch 24] Step 450/737 - Loss: 0.2367\n[Epoch 24] Step 500/737 - Loss: 0.2358\n[Epoch 24] Step 550/737 - Loss: 0.1612\n[Epoch 24] Step 600/737 - Loss: 0.2051\n[Epoch 24] Step 650/737 - Loss: 0.1213\n[Epoch 24] Step 700/737 - Loss: 0.1617\nEpoch 024 | TrainLoss(step): 0.1424 | TrainLoss(eval): 0.1245 | ValLoss: 1.0433 | Train mIoU: 0.6095 | Val mIoU: 0.2465 | Val Dice: 2.4392 | Val F1: 0.3520 | Val Acc: 0.7875 | LR: 0.000006\n  -> Checkpoint saved to unet_checkpoint_epoch_24.pth\n\n===== Epoch 25/40 =====\n[Epoch 25] Step 1/737 - Loss: 0.1179\n[Epoch 25] Step 50/737 - Loss: 0.1524\n[Epoch 25] Step 100/737 - Loss: 0.1796\n[Epoch 25] Step 150/737 - Loss: 0.1529\n[Epoch 25] Step 200/737 - Loss: 0.0833\n[Epoch 25] Step 250/737 - Loss: 0.2490\n[Epoch 25] Step 300/737 - Loss: 0.0947\n[Epoch 25] Step 350/737 - Loss: 0.0898\n[Epoch 25] Step 400/737 - Loss: 0.1277\n[Epoch 25] Step 450/737 - Loss: 0.1008\n[Epoch 25] Step 500/737 - Loss: 0.1049\n[Epoch 25] Step 550/737 - Loss: 0.1246\n[Epoch 25] Step 600/737 - Loss: 0.1326\n[Epoch 25] Step 650/737 - Loss: 0.1394\n[Epoch 25] Step 700/737 - Loss: 0.2420\nEpoch 025 | TrainLoss(step): 0.1395 | TrainLoss(eval): 0.1238 | ValLoss: 1.0409 | Train mIoU: 0.6117 | Val mIoU: 0.2494 | Val Dice: 2.4714 | Val F1: 0.3553 | Val Acc: 0.7872 | LR: 0.000006\n\n===== Epoch 26/40 =====\n[Epoch 26] Step 1/737 - Loss: 0.1851\n[Epoch 26] Step 50/737 - Loss: 0.1114\n[Epoch 26] Step 100/737 - Loss: 0.1643\n[Epoch 26] Step 150/737 - Loss: 0.2275\n[Epoch 26] Step 200/737 - Loss: 0.1743\n[Epoch 26] Step 250/737 - Loss: 0.1022\n[Epoch 26] Step 300/737 - Loss: 0.1086\n[Epoch 26] Step 350/737 - Loss: 0.1224\n[Epoch 26] Step 400/737 - Loss: 0.1170\n[Epoch 26] Step 450/737 - Loss: 0.1302\n[Epoch 26] Step 500/737 - Loss: 0.1723\n[Epoch 26] Step 550/737 - Loss: 0.0896\n[Epoch 26] Step 600/737 - Loss: 0.0713\n[Epoch 26] Step 650/737 - Loss: 0.1830\n[Epoch 26] Step 700/737 - Loss: 0.2265\nEpoch 026 | TrainLoss(step): 0.1364 | TrainLoss(eval): 0.1273 | ValLoss: 1.0633 | Train mIoU: 0.6136 | Val mIoU: 0.2444 | Val Dice: 2.3922 | Val F1: 0.3503 | Val Acc: 0.7864 | LR: 0.000003\n  -> Checkpoint saved to unet_checkpoint_epoch_26.pth\n\n===== Epoch 27/40 =====\n[Epoch 27] Step 1/737 - Loss: 0.1781\n[Epoch 27] Step 50/737 - Loss: 0.1279\n[Epoch 27] Step 100/737 - Loss: 0.1186\n[Epoch 27] Step 150/737 - Loss: 0.1894\n[Epoch 27] Step 200/737 - Loss: 0.1095\n[Epoch 27] Step 250/737 - Loss: 0.1167\n[Epoch 27] Step 300/737 - Loss: 0.1724\n[Epoch 27] Step 350/737 - Loss: 0.1098\n[Epoch 27] Step 400/737 - Loss: 0.3462\n[Epoch 27] Step 450/737 - Loss: 0.0997\n[Epoch 27] Step 500/737 - Loss: 0.1697\n[Epoch 27] Step 550/737 - Loss: 0.1383\n[Epoch 27] Step 600/737 - Loss: 0.1201\n[Epoch 27] Step 650/737 - Loss: 0.0979\n[Epoch 27] Step 700/737 - Loss: 0.0863\nEpoch 027 | TrainLoss(step): 0.1339 | TrainLoss(eval): 0.1227 | ValLoss: 1.0830 | Train mIoU: 0.6163 | Val mIoU: 0.2451 | Val Dice: 2.3663 | Val F1: 0.3509 | Val Acc: 0.7882 | LR: 0.000003\n\n===== Epoch 28/40 =====\n[Epoch 28] Step 1/737 - Loss: 0.1295\n[Epoch 28] Step 50/737 - Loss: 0.1261\n[Epoch 28] Step 100/737 - Loss: 0.1652\n[Epoch 28] Step 150/737 - Loss: 0.0991\n[Epoch 28] Step 200/737 - Loss: 0.1199\n[Epoch 28] Step 250/737 - Loss: 0.1599\n[Epoch 28] Step 300/737 - Loss: 0.1312\n[Epoch 28] Step 350/737 - Loss: 0.0992\n[Epoch 28] Step 400/737 - Loss: 0.1404\n[Epoch 28] Step 550/737 - Loss: 0.1086\n[Epoch 28] Step 600/737 - Loss: 0.0917\n[Epoch 28] Step 650/737 - Loss: 0.1338\n[Epoch 28] Step 700/737 - Loss: 0.1382\nEpoch 028 | TrainLoss(step): 0.1325 | TrainLoss(eval): 0.1179 | ValLoss: 1.0646 | Train mIoU: 0.6211 | Val mIoU: 0.2468 | Val Dice: 2.4287 | Val F1: 0.3534 | Val Acc: 0.7860 | LR: 0.000003\n  -> Checkpoint saved to unet_checkpoint_epoch_28.pth\n\n===== Epoch 29/40 =====\n[Epoch 29] Step 1/737 - Loss: 0.1551\n[Epoch 29] Step 50/737 - Loss: 0.1007\n[Epoch 29] Step 100/737 - Loss: 0.0974\n[Epoch 29] Step 150/737 - Loss: 0.2926\n[Epoch 29] Step 200/737 - Loss: 0.0873\n[Epoch 29] Step 250/737 - Loss: 0.1346\n[Epoch 29] Step 300/737 - Loss: 0.0989\n[Epoch 29] Step 350/737 - Loss: 0.0961\n[Epoch 29] Step 400/737 - Loss: 0.1914\n[Epoch 29] Step 450/737 - Loss: 0.1157\n[Epoch 29] Step 500/737 - Loss: 0.1376\n[Epoch 29] Step 550/737 - Loss: 0.1256\n[Epoch 29] Step 600/737 - Loss: 0.0672\n[Epoch 29] Step 650/737 - Loss: 0.0902\n[Epoch 29] Step 700/737 - Loss: 0.2000\nEpoch 029 | TrainLoss(step): 0.1316 | TrainLoss(eval): 0.1214 | ValLoss: 1.0881 | Train mIoU: 0.6190 | Val mIoU: 0.2464 | Val Dice: 2.4110 | Val F1: 0.3523 | Val Acc: 0.7873 | LR: 0.000003\n\n===== Epoch 30/40 =====\n[Epoch 30] Step 1/737 - Loss: 0.0845\n[Epoch 30] Step 50/737 - Loss: 0.1617\n[Epoch 30] Step 100/737 - Loss: 0.0749\n[Epoch 30] Step 150/737 - Loss: 0.1258\n[Epoch 30] Step 200/737 - Loss: 0.0738\n[Epoch 30] Step 250/737 - Loss: 0.1758\n[Epoch 30] Step 300/737 - Loss: 0.1073\n[Epoch 30] Step 350/737 - Loss: 0.0783\n[Epoch 30] Step 400/737 - Loss: 0.1061\n[Epoch 30] Step 450/737 - Loss: 0.1318\n[Epoch 30] Step 500/737 - Loss: 0.0892\n[Epoch 30] Step 550/737 - Loss: 0.1145\n[Epoch 30] Step 600/737 - Loss: 0.2153\n[Epoch 30] Step 650/737 - Loss: 0.2676\n[Epoch 30] Step 700/737 - Loss: 0.1750\nEpoch 030 | TrainLoss(step): 0.1293 | TrainLoss(eval): 0.1147 | ValLoss: 1.0715 | Train mIoU: 0.6251 | Val mIoU: 0.2489 | Val Dice: 2.4450 | Val F1: 0.3568 | Val Acc: 0.7865 | LR: 0.000002\n  -> Checkpoint saved to unet_checkpoint_epoch_30.pth\n\n===== Epoch 31/40 =====\n[Epoch 31] Step 1/737 - Loss: 0.1461\n[Epoch 31] Step 50/737 - Loss: 0.1159\n[Epoch 31] Step 100/737 - Loss: 0.1601\n[Epoch 31] Step 150/737 - Loss: 0.0965\n[Epoch 31] Step 200/737 - Loss: 0.1343\n[Epoch 31] Step 250/737 - Loss: 0.1408\n[Epoch 31] Step 300/737 - Loss: 0.1582\n[Epoch 31] Step 350/737 - Loss: 0.1366\n[Epoch 31] Step 400/737 - Loss: 0.1507\n[Epoch 31] Step 450/737 - Loss: 0.0822\n[Epoch 31] Step 500/737 - Loss: 0.1676\n[Epoch 31] Step 550/737 - Loss: 0.1354\n[Epoch 31] Step 600/737 - Loss: 0.1566\n[Epoch 31] Step 650/737 - Loss: 0.1439\n[Epoch 31] Step 700/737 - Loss: 0.1061\nEpoch 031 | TrainLoss(step): 0.1284 | TrainLoss(eval): 0.1157 | ValLoss: 1.0985 | Train mIoU: 0.6249 | Val mIoU: 0.2494 | Val Dice: 2.4291 | Val F1: 0.3573 | Val Acc: 0.7865 | LR: 0.000002\n\n===== Epoch 32/40 =====\n[Epoch 32] Step 1/737 - Loss: 0.1264\n[Epoch 32] Step 50/737 - Loss: 0.0971\n[Epoch 32] Step 100/737 - Loss: 0.1280\n[Epoch 32] Step 150/737 - Loss: 0.1056\n[Epoch 32] Step 200/737 - Loss: 0.1128\n[Epoch 32] Step 250/737 - Loss: 0.1006\n[Epoch 32] Step 300/737 - Loss: 0.1633\n[Epoch 32] Step 350/737 - Loss: 0.0978\n[Epoch 32] Step 400/737 - Loss: 0.1543\n[Epoch 32] Step 450/737 - Loss: 0.0680\n[Epoch 32] Step 500/737 - Loss: 0.1064\n[Epoch 32] Step 550/737 - Loss: 0.1185\n[Epoch 32] Step 600/737 - Loss: 0.1249\n[Epoch 32] Step 650/737 - Loss: 0.1372\n[Epoch 32] Step 700/737 - Loss: 0.1118\nEpoch 032 | TrainLoss(step): 0.1277 | TrainLoss(eval): 0.1146 | ValLoss: 1.0844 | Train mIoU: 0.6227 | Val mIoU: 0.2480 | Val Dice: 2.4251 | Val F1: 0.3550 | Val Acc: 0.7881 | LR: 0.000002\n  -> Checkpoint saved to unet_checkpoint_epoch_32.pth\n\n===== Epoch 33/40 =====\n[Epoch 33] Step 1/737 - Loss: 0.1165\n[Epoch 33] Step 50/737 - Loss: 0.0953\n[Epoch 33] Step 100/737 - Loss: 0.0860\n[Epoch 33] Step 150/737 - Loss: 0.1546\n[Epoch 33] Step 200/737 - Loss: 0.0749\n[Epoch 33] Step 250/737 - Loss: 0.1016\n[Epoch 33] Step 300/737 - Loss: 0.0741\n[Epoch 33] Step 350/737 - Loss: 0.1282\n[Epoch 33] Step 400/737 - Loss: 0.1193\n[Epoch 33] Step 450/737 - Loss: 0.0741\n[Epoch 33] Step 500/737 - Loss: 0.1625\n[Epoch 33] Step 550/737 - Loss: 0.1422\n[Epoch 33] Step 600/737 - Loss: 0.1176\n[Epoch 33] Step 650/737 - Loss: 0.1144\n[Epoch 33] Step 700/737 - Loss: 0.1125\nEpoch 033 | TrainLoss(step): 0.1264 | TrainLoss(eval): 0.1164 | ValLoss: 1.0886 | Train mIoU: 0.6254 | Val mIoU: 0.2473 | Val Dice: 2.4274 | Val F1: 0.3544 | Val Acc: 0.7863 | LR: 0.000002\n\n===== Epoch 34/40 =====\n[Epoch 34] Step 1/737 - Loss: 0.1710\n[Epoch 34] Step 50/737 - Loss: 0.0815\n[Epoch 34] Step 100/737 - Loss: 0.1727\n[Epoch 34] Step 150/737 - Loss: 0.1500\n[Epoch 34] Step 200/737 - Loss: 0.0936\n[Epoch 34] Step 250/737 - Loss: 0.0912\n[Epoch 34] Step 300/737 - Loss: 0.1381\n[Epoch 34] Step 350/737 - Loss: 0.0789\n[Epoch 34] Step 400/737 - Loss: 0.1253\n[Epoch 34] Step 450/737 - Loss: 0.1761\n[Epoch 34] Step 500/737 - Loss: 0.1624\n[Epoch 34] Step 550/737 - Loss: 0.0752\n[Epoch 34] Step 600/737 - Loss: 0.0888\n[Epoch 34] Step 650/737 - Loss: 0.1866\n[Epoch 34] Step 700/737 - Loss: 0.1062\nEpoch 034 | TrainLoss(step): 0.1267 | TrainLoss(eval): 0.1120 | ValLoss: 1.1045 | Train mIoU: 0.6278 | Val mIoU: 0.2458 | Val Dice: 2.3761 | Val F1: 0.3524 | Val Acc: 0.7877 | LR: 0.000001\n  -> Checkpoint saved to unet_checkpoint_epoch_34.pth\n\n===== Epoch 35/40 =====\n[Epoch 35] Step 1/737 - Loss: 0.1058\n[Epoch 35] Step 50/737 - Loss: 0.0792\n[Epoch 35] Step 100/737 - Loss: 0.1485\n[Epoch 35] Step 150/737 - Loss: 0.0727\n[Epoch 35] Step 200/737 - Loss: 0.0763\n[Epoch 35] Step 250/737 - Loss: 0.1196\n[Epoch 35] Step 300/737 - Loss: 0.1321\n[Epoch 35] Step 350/737 - Loss: 0.1192\n[Epoch 35] Step 400/737 - Loss: 0.0955\n[Epoch 35] Step 450/737 - Loss: 0.2743\n[Epoch 35] Step 500/737 - Loss: 0.1543\n[Epoch 35] Step 550/737 - Loss: 0.0579\n[Epoch 35] Step 600/737 - Loss: 0.1242\n[Epoch 35] Step 650/737 - Loss: 0.0850\n[Epoch 35] Step 700/737 - Loss: 0.1201\nEpoch 035 | TrainLoss(step): 0.1269 | TrainLoss(eval): 0.1120 | ValLoss: 1.0795 | Train mIoU: 0.6267 | Val mIoU: 0.2465 | Val Dice: 2.4228 | Val F1: 0.3533 | Val Acc: 0.7868 | LR: 0.000001\n\n===== Epoch 36/40 =====\n[Epoch 36] Step 1/737 - Loss: 0.0448\n[Epoch 36] Step 50/737 - Loss: 0.0695\n[Epoch 36] Step 100/737 - Loss: 0.1240\n[Epoch 36] Step 150/737 - Loss: 0.1011\n[Epoch 36] Step 200/737 - Loss: 0.0943\n[Epoch 36] Step 250/737 - Loss: 0.0785\n[Epoch 36] Step 300/737 - Loss: 0.0996\n[Epoch 36] Step 350/737 - Loss: 0.1492\n[Epoch 36] Step 400/737 - Loss: 0.0879\n[Epoch 36] Step 450/737 - Loss: 0.0916\n[Epoch 36] Step 500/737 - Loss: 0.1773\n[Epoch 36] Step 550/737 - Loss: 0.0822\n[Epoch 36] Step 600/737 - Loss: 0.1300\n[Epoch 36] Step 650/737 - Loss: 0.0937\n[Epoch 36] Step 700/737 - Loss: 0.1494\nEpoch 036 | TrainLoss(step): 0.1254 | TrainLoss(eval): 0.1127 | ValLoss: 1.0955 | Train mIoU: 0.6278 | Val mIoU: 0.2471 | Val Dice: 2.3959 | Val F1: 0.3547 | Val Acc: 0.7866 | LR: 0.000001\n  -> Checkpoint saved to unet_checkpoint_epoch_36.pth\n\n===== Epoch 37/40 =====\n[Epoch 37] Step 1/737 - Loss: 0.1192\n[Epoch 37] Step 50/737 - Loss: 0.0646\n[Epoch 37] Step 100/737 - Loss: 0.1218\n[Epoch 37] Step 150/737 - Loss: 0.0873\n[Epoch 37] Step 200/737 - Loss: 0.0958\n[Epoch 37] Step 250/737 - Loss: 0.2146\n[Epoch 37] Step 300/737 - Loss: 0.1101\n[Epoch 37] Step 350/737 - Loss: 0.0780\n[Epoch 37] Step 400/737 - Loss: 0.1914\n[Epoch 37] Step 450/737 - Loss: 0.0611\n[Epoch 37] Step 500/737 - Loss: 0.1308\n[Epoch 37] Step 550/737 - Loss: 0.1898\n[Epoch 37] Step 600/737 - Loss: 0.0981\n[Epoch 37] Step 650/737 - Loss: 0.0990\n[Epoch 37] Step 700/737 - Loss: 0.1426\nEpoch 037 | TrainLoss(step): 0.1248 | TrainLoss(eval): 0.1148 | ValLoss: 1.1060 | Train mIoU: 0.6278 | Val mIoU: 0.2466 | Val Dice: 2.3914 | Val F1: 0.3545 | Val Acc: 0.7870 | LR: 0.000001\n\n===== Epoch 38/40 =====\n[Epoch 38] Step 1/737 - Loss: 0.1575\n[Epoch 38] Step 50/737 - Loss: 0.1357\n[Epoch 38] Step 100/737 - Loss: 0.1238\n[Epoch 38] Step 150/737 - Loss: 0.1196\n[Epoch 38] Step 200/737 - Loss: 0.0803\n[Epoch 38] Step 250/737 - Loss: 0.0526\n[Epoch 38] Step 300/737 - Loss: 0.0470\n[Epoch 38] Step 350/737 - Loss: 0.1204\n[Epoch 38] Step 400/737 - Loss: 0.1443\n[Epoch 38] Step 450/737 - Loss: 0.1467\n[Epoch 38] Step 500/737 - Loss: 0.1464\n[Epoch 38] Step 550/737 - Loss: 0.1335\n[Epoch 38] Step 600/737 - Loss: 0.1444\n[Epoch 38] Step 650/737 - Loss: 0.1550\n[Epoch 38] Step 700/737 - Loss: 0.1005\nEpoch 038 | TrainLoss(step): 0.1249 | TrainLoss(eval): 0.1123 | ValLoss: 1.0924 | Train mIoU: 0.6293 | Val mIoU: 0.2501 | Val Dice: 2.4342 | Val F1: 0.3590 | Val Acc: 0.7848 | LR: 0.000000\n  -> Checkpoint saved to unet_checkpoint_epoch_38.pth\n\n===== Epoch 39/40 =====\n[Epoch 39] Step 1/737 - Loss: 0.0466\n[Epoch 39] Step 50/737 - Loss: 0.1856\n[Epoch 39] Step 100/737 - Loss: 0.1540\n[Epoch 39] Step 150/737 - Loss: 0.1346\n[Epoch 39] Step 200/737 - Loss: 0.0920\n[Epoch 39] Step 250/737 - Loss: 0.2403\n[Epoch 39] Step 300/737 - Loss: 0.1440\n[Epoch 39] Step 350/737 - Loss: 0.1576\n[Epoch 39] Step 400/737 - Loss: 0.0876\n[Epoch 39] Step 450/737 - Loss: 0.1434\n[Epoch 39] Step 500/737 - Loss: 0.1793\n[Epoch 39] Step 550/737 - Loss: 0.0489\n[Epoch 39] Step 600/737 - Loss: 0.0924\n[Epoch 39] Step 650/737 - Loss: 0.1101\n[Epoch 39] Step 700/737 - Loss: 0.1414\nEpoch 039 | TrainLoss(step): 0.1243 | TrainLoss(eval): 0.1149 | ValLoss: 1.1116 | Train mIoU: 0.6290 | Val mIoU: 0.2479 | Val Dice: 2.3776 | Val F1: 0.3561 | Val Acc: 0.7865 | LR: 0.000000\n\n===== Epoch 40/40 =====\n[Epoch 40] Step 1/737 - Loss: 0.1864\n[Epoch 40] Step 50/737 - Loss: 0.0927\n[Epoch 40] Step 100/737 - Loss: 0.1245\n[Epoch 40] Step 150/737 - Loss: 0.2382\n[Epoch 40] Step 200/737 - Loss: 0.1327\n[Epoch 40] Step 250/737 - Loss: 0.0906\n[Epoch 40] Step 300/737 - Loss: 0.2052\n[Epoch 40] Step 350/737 - Loss: 0.2093\n[Epoch 40] Step 400/737 - Loss: 0.1192\n[Epoch 40] Step 450/737 - Loss: 0.0860\n[Epoch 40] Step 500/737 - Loss: 0.0920\n[Epoch 40] Step 550/737 - Loss: 0.0980\n[Epoch 40] Step 600/737 - Loss: 0.0706\n[Epoch 40] Step 650/737 - Loss: 0.1033\n[Epoch 40] Step 700/737 - Loss: 0.1662\nEpoch 040 | TrainLoss(step): 0.1255 | TrainLoss(eval): 0.1131 | ValLoss: 1.0974 | Train mIoU: 0.6279 | Val mIoU: 0.2505 | Val Dice: 2.4515 | Val F1: 0.3588 | Val Acc: 0.7851 | LR: 0.000000\n  -> Checkpoint saved to unet_checkpoint_epoch_40.pth\n\nTraining complete. Best mIoU: 0.2508009672164917\nSaved metrics to: /kaggle/working/unet_results.json\n","output_type":"stream"},{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/unet_results.json","text/html":"<a href='/kaggle/working/unet_results.json' target='_blank'>/kaggle/working/unet_results.json</a><br>"},"metadata":{}}],"execution_count":31},{"cell_type":"code","source":"!zip -r /kaggle/working/unet_outputs.zip /kaggle/working","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-21T20:23:11.237256Z","iopub.execute_input":"2025-11-21T20:23:11.237883Z","iopub.status.idle":"2025-11-21T20:29:11.819131Z","shell.execute_reply.started":"2025-11-21T20:23:11.237849Z","shell.execute_reply":"2025-11-21T20:29:11.818311Z"}},"outputs":[{"name":"stdout","text":"  adding: kaggle/working/ (stored 0%)\n  adding: kaggle/working/unet_checkpoint_epoch_18.pth (deflated 8%)\n  adding: kaggle/working/unet_checkpoint_epoch_14.pth (deflated 8%)\n  adding: kaggle/working/unet_checkpoint_epoch_34.pth (deflated 8%)\n  adding: kaggle/working/unet_checkpoint_epoch_40.pth (deflated 8%)\n  adding: kaggle/working/unet_checkpoint_epoch_38.pth (deflated 8%)\n  adding: kaggle/working/unet_best_miou.pth (deflated 7%)\n  adding: kaggle/working/unet_checkpoint_epoch_28.pth (deflated 8%)\n  adding: kaggle/working/unet_checkpoint_epoch_26.pth (deflated 8%)\n  adding: kaggle/working/unet_checkpoint_epoch_10.pth (deflated 8%)\n  adding: kaggle/working/unet_last.pth (deflated 8%)\n  adding: kaggle/working/unet_checkpoint_epoch_24.pth (deflated 8%)\n  adding: kaggle/working/.virtual_documents/ (stored 0%)\n  adding: kaggle/working/unet_checkpoint_epoch_6.pth (deflated 8%)\n  adding: kaggle/working/unet_checkpoint_epoch_16.pth (deflated 8%)\n  adding: kaggle/working/unet_checkpoint_epoch_4.pth (deflated 8%)\n  adding: kaggle/working/unet_checkpoint_epoch_36.pth (deflated 8%)\n  adding: kaggle/working/unet_checkpoint_epoch_12.pth (deflated 8%)\n  adding: kaggle/working/unet_checkpoint_epoch_30.pth (deflated 8%)\n  adding: kaggle/working/unet_checkpoint_epoch_2.pth (deflated 8%)\n  adding: kaggle/working/unet_checkpoint_epoch_20.pth (deflated 8%)\n  adding: kaggle/working/unet_checkpoint_epoch_22.pth (deflated 8%)\n  adding: kaggle/working/unet_checkpoint_epoch_8.pth (deflated 8%)\n  adding: kaggle/working/unet_results.json (deflated 75%)\n  adding: kaggle/working/unet_checkpoint_epoch_32.pth (deflated 8%)\n","output_type":"stream"}],"execution_count":32}]}