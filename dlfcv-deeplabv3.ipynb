{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":13803291,"sourceType":"datasetVersion","datasetId":8788812},{"sourceId":13804249,"sourceType":"datasetVersion","datasetId":8789516}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Imports**","metadata":{}},{"cell_type":"code","source":"!pip install -q segmentation-models-pytorch torchmetrics transformers","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-22T14:15:17.226745Z","iopub.execute_input":"2025-11-22T14:15:17.227473Z","iopub.status.idle":"2025-11-22T14:16:32.411510Z","shell.execute_reply.started":"2025-11-22T14:15:17.227447Z","shell.execute_reply":"2025-11-22T14:16:32.410488Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.8/154.8 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m104.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m76.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m43.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m31.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m87.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nlibcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import json\nfrom pathlib import Path\n\nimport torch\nfrom torch import nn\nfrom torch.utils.data import DataLoader, Dataset\n\nimport segmentation_models_pytorch as smp\nfrom torchmetrics import JaccardIndex, Accuracy, F1Score\nfrom torchmetrics.segmentation import DiceScore\nfrom torchvision import transforms\nfrom torchvision.transforms import InterpolationMode\nfrom torch.amp import GradScaler, autocast\n\nfrom PIL import Image\nimport numpy as np\n\nfrom IPython.display import FileLink\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Device:\", device)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-22T14:17:28.800702Z","iopub.execute_input":"2025-11-22T14:17:28.801192Z","iopub.status.idle":"2025-11-22T14:17:28.806810Z","shell.execute_reply.started":"2025-11-22T14:17:28.801168Z","shell.execute_reply":"2025-11-22T14:17:28.806033Z"}},"outputs":[{"name":"stdout","text":"Device: cuda\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"# **Setup**","metadata":{}},{"cell_type":"markdown","source":"## **Dataset**","metadata":{}},{"cell_type":"code","source":"# Initial setup\nDATA_ROOT = Path(\"/kaggle/input/data-clean\")\nIMG_DIR = DATA_ROOT / \"images\"\nMSK_DIR = DATA_ROOT / \"masks\"\n\ntrain_img_dir = IMG_DIR / \"train\"\nval_img_dir   = IMG_DIR / \"validation\"\ntest_img_dir  = IMG_DIR / \"test\"\n\ntrain_msk_dir = MSK_DIR / \"train\"\nval_msk_dir   = MSK_DIR / \"validation\"\ntest_msk_dir  = MSK_DIR / \"test\"\n\nCONFIG = {\n    \"experiment_name\": \"deeplabv3plus_resnet50_dacl10k_512\",\n    \"model\": \"DeepLabV3Plus\",\n    \"encoder\": \"resnet50\",          # or keep resnet34 if you want lighter\n    \"encoder_weights\": \"imagenet\",\n    \"num_classes\": 14,\n    \"image_size\": [512, 512],\n    \"batch_size\": 8,                # if you hit OOM, drop to 4\n    \"epochs\": 40,\n    \"learning_rate\": 1e-4,\n    \"loss\": \"CrossEntropyLoss\",\n    \"optimizer\": \"Adam\",\n    \"scheduler\": \"ReduceLROnPlateau\",\n    \"metrics\": [\n        \"mean_iou_per_class\",\n        \"dice_macro\",\n        \"f1_macro\",\n        \"global_pixel_accuracy\",\n    ],\n}\n\n\nNUM_CLASSES = CONFIG[\"num_classes\"]\nBATCH_SIZE  = CONFIG[\"batch_size\"]\nEPOCHS      = CONFIG[\"epochs\"]\nLR          = CONFIG[\"learning_rate\"]\nIMAGE_SIZE  = CONFIG[\"image_size\"]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-22T14:29:32.454262Z","iopub.execute_input":"2025-11-22T14:29:32.454954Z","iopub.status.idle":"2025-11-22T14:29:32.460411Z","shell.execute_reply.started":"2025-11-22T14:29:32.454930Z","shell.execute_reply":"2025-11-22T14:29:32.459793Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# Dataset setup\nclass Dacl10kDataset(Dataset):\n    def __init__(self, img_dir, msk_dir, image_size=(512, 512)):\n        self.img_dir = Path(img_dir)\n        self.msk_dir = Path(msk_dir)\n        self.image_size = image_size\n\n        self.img_paths = sorted([p for p in self.img_dir.iterdir()])\n\n        # Transformations for training images\n        self.img_transform = transforms.Compose([\n            transforms.Resize(self.image_size, interpolation=transforms.InterpolationMode.BILINEAR),\n            transforms.ToTensor(),\n            transforms.Normalize(  # Normalize each channel with ImageNet normalization values\n                mean=[0.485, 0.456, 0.406],\n                std=[0.229, 0.224, 0.225],\n            ),\n        ])\n\n        self.mask_resize = transforms.Resize(\n            self.image_size,\n            interpolation=transforms.InterpolationMode.NEAREST, # Change interpolation value to keep integers\n        )\n\n    def __len__(self):\n        return len(self.img_paths)\n\n    def __getitem__(self, idx):\n        img_path = self.img_paths[idx]\n        msk_path = self.msk_dir / img_path.name.replace(\"jpg\", \"png\") # same filename, jpg -> png\n\n        # Image\n        img = Image.open(img_path).convert(\"RGB\")\n        img = self.img_transform(img)\n\n        # Mask\n        mask = Image.open(msk_path)\n        mask = self.mask_resize(mask)\n        mask = torch.from_numpy(np.array(mask, dtype=np.int64))  # [H, W] long with 0..13\n\n        return img, mask","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-22T14:29:34.507784Z","iopub.execute_input":"2025-11-22T14:29:34.508368Z","iopub.status.idle":"2025-11-22T14:29:34.514982Z","shell.execute_reply.started":"2025-11-22T14:29:34.508343Z","shell.execute_reply":"2025-11-22T14:29:34.514255Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# Dataset definition\ntrain_dataset = Dacl10kDataset(train_img_dir, train_msk_dir, IMAGE_SIZE)\nval_dataset   = Dacl10kDataset(val_img_dir,   val_msk_dir,   IMAGE_SIZE)\n\ntrain_loader = DataLoader(\n    train_dataset,\n    batch_size=BATCH_SIZE,\n    shuffle=True,\n    num_workers=2,\n    pin_memory=True,\n)\n\nval_loader = DataLoader(\n    val_dataset,\n    batch_size=BATCH_SIZE,\n    shuffle=False,\n    num_workers=2,\n    pin_memory=True,\n)\n\nprint(\"Train samples:\", len(train_dataset), \" | batches:\", len(train_loader))\nprint(\"Val samples:  \", len(val_dataset),   \" | batches:\", len(val_loader))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-22T14:29:39.322855Z","iopub.execute_input":"2025-11-22T14:29:39.323543Z","iopub.status.idle":"2025-11-22T14:29:39.421569Z","shell.execute_reply.started":"2025-11-22T14:29:39.323519Z","shell.execute_reply":"2025-11-22T14:29:39.420785Z"}},"outputs":[{"name":"stdout","text":"Train samples: 5895  | batches: 737\nVal samples:   1040  | batches: 130\n","output_type":"stream"}],"execution_count":8},{"cell_type":"markdown","source":"## **Model, loss, optimizer, metrics**","metadata":{}},{"cell_type":"code","source":"# Model\nmodel = smp.DeepLabV3Plus(\n    encoder_name=CONFIG[\"encoder\"],\n    encoder_weights=CONFIG[\"encoder_weights\"],\n    in_channels=3,\n    classes=NUM_CLASSES,\n).to(device)\n\n# Loss and optimizer. Scheduler will decrease learning rate bu half when val_loss does not improve fort 3 epochs\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=LR)\nscheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n    optimizer,\n    mode=\"min\",\n    factor=0.5,\n    patience=3,\n    verbose=True,\n)\n\n# Metrics\n# 1) Mean IoU per class (Jaccard)\nmiou_metric = JaccardIndex(\n    task=\"multiclass\",\n    num_classes=NUM_CLASSES,\n).to(device)\n\n# 2) Dice score (macro over classes)\ndice_metric = DiceScore(\n    num_classes=NUM_CLASSES,\n    average=\"macro\",\n).to(device)\n\n# 3) F1 Score (macro over classes)\nf1_metric = F1Score(\n    task=\"multiclass\",\n    num_classes=NUM_CLASSES,\n    average=\"macro\",\n).to(device)\n\n# 4) Global Pixel Accuracy\nacc_metric = Accuracy(\n    task=\"multiclass\",\n    num_classes=NUM_CLASSES,\n).to(device)\n\nprint(\"DeepLabV3+ params (M):\", sum(p.numel() for p in model.parameters()) / 1e6)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-22T14:29:41.620741Z","iopub.execute_input":"2025-11-22T14:29:41.621436Z","iopub.status.idle":"2025-11-22T14:29:43.923125Z","shell.execute_reply.started":"2025-11-22T14:29:41.621410Z","shell.execute_reply":"2025-11-22T14:29:43.922319Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/156 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1ee7fe01605a4e5898eb00d2cf95be2d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/102M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0e866996ad1b4c1cbe0de8fd27d1f1cc"}},"metadata":{}},{"name":"stdout","text":"DeepLabV3+ params (M): 26.680926\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"scaler = GradScaler(enabled=(device.type == \"cuda\")) # Uses AMP to speed up training\n\nCHECKPOINT_EVERY = 2  # epochs\n\ndef train_one_epoch(model, loader, optimizer, criterion, epoch):\n    model.train() # set model to training mode\n    running_loss = 0.0 # start total loss at 0.0\n\n    for step, (images, masks) in enumerate(loader, start=1):\n        images = images.to(device, non_blocking=True)\n        masks  = masks.to(device, non_blocking=True)\n\n        optimizer.zero_grad() # zero the gradients\n\n         # Uses AMP to speed up training\n        with autocast(device_type=\"cuda\", enabled=(device.type == \"cuda\")):\n            outputs = model(images)           \n            loss = criterion(outputs, masks)\n\n        scaler.scale(loss).backward()\n        scaler.step(optimizer)\n        scaler.update()\n\n        running_loss += loss.item() # add losses in each step\n\n        if step % 50 == 0 or step == 1:\n            print(f\"[Epoch {epoch}] Step {step}/{len(loader)} - Loss: {loss.item():.4f}\")\n\n    return running_loss / len(loader) # return mean loss across an epoch\n\n\n@torch.no_grad()\ndef evaluate(model, loader, criterion):\n    model.eval()\n    val_loss = 0.0\n\n    # Reset metrics each evaluation\n    miou_metric.reset()\n    dice_metric.reset()\n    f1_metric.reset()\n    acc_metric.reset()\n\n    for images, masks in loader:\n        images = images.to(device, non_blocking=True)\n        masks  = masks.to(device, non_blocking=True)\n\n        # Uses AMP to speed up training\n        with autocast(device_type=\"cuda\", enabled=(device.type == \"cuda\")):\n            outputs = model(images)\n            loss = criterion(outputs, masks)\n\n        val_loss += loss.item()\n\n        preds = torch.argmax(outputs, dim=1)  # Get class index with highest probability\n\n        # Update metrics \n        miou_metric.update(preds, masks)\n        dice_metric.update(preds, masks)\n        f1_metric.update(preds, masks)\n        acc_metric.update(preds, masks)\n\n    val_loss /= len(loader) # compute mean loss\n\n    miou = miou_metric.compute().item()   # mean IoU per class\n    dice = dice_metric.compute().item()   # macro Dice\n    mf1  = f1_metric.compute().item()     # macro F1\n    acc  = acc_metric.compute().item()    # global pixel accuracy\n\n    return val_loss, miou, dice, mf1, acc\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-22T14:33:51.281452Z","iopub.execute_input":"2025-11-22T14:33:51.282001Z","iopub.status.idle":"2025-11-22T14:33:51.290669Z","shell.execute_reply.started":"2025-11-22T14:33:51.281958Z","shell.execute_reply":"2025-11-22T14:33:51.290096Z"}},"outputs":[],"execution_count":14},{"cell_type":"markdown","source":"# **Train**","metadata":{}},{"cell_type":"code","source":"history = [] \nbest_miou = 0.0\n\nfor epoch in range(1, EPOCHS + 1):\n    print(f\"\\n===== Epoch {epoch}/{EPOCHS} =====\")\n\n    # Training epoch\n    train_loss = train_one_epoch(model, train_loader, optimizer, criterion, epoch)\n\n    # Metrics for train and validation sets\n    train_loss_eval, train_miou, train_dice, train_f1, train_acc = evaluate(model, train_loader, criterion)\n    val_loss, val_miou, val_dice, val_f1, val_acc = evaluate(model, val_loader, criterion)\n\n    # step scheduler on val_loss\n    scheduler.step(val_loss)\n\n    current_lr = optimizer.param_groups[0][\"lr\"]\n    \n    print(\n        f\"Epoch {epoch:03d} | \"\n        f\"TrainLoss(step): {train_loss:.4f} | \"\n        f\"TrainLoss(eval): {train_loss_eval:.4f} | \"\n        f\"ValLoss: {val_loss:.4f} | \"\n        f\"Train mIoU: {train_miou:.4f} | \"\n        f\"Val mIoU: {val_miou:.4f} | \"\n        f\"Val Dice: {val_dice:.4f} | \"\n        f\"Val F1: {val_f1:.4f} | \"\n        f\"Val Acc: {val_acc:.4f} | \"\n        f\"LR: {current_lr:.6f}\"\n    )\n\n    # Store metrics\n    history.append({\n        \"epoch\": epoch,\n        # training loss from the actual training loop\n        \"train_loss_step\": float(train_loss),\n        # training loss recomputed in eval mode (no dropout, BN in eval)\n        \"train_loss_eval\": float(train_loss_eval),\n        \"train_miou\": float(train_miou),\n        \"train_dice\": float(train_dice),\n        \"train_f1_macro\": float(train_f1),\n        \"train_global_pixel_accuracy\": float(train_acc),\n        \"val_loss\": float(val_loss),\n        \"val_miou\": float(val_miou),\n        \"val_dice\": float(val_dice),\n        \"val_f1_macro\": float(val_f1),\n        \"val_global_pixel_accuracy\": float(val_acc),\n        \"lr\": float(current_lr),\n    })\n\n    # save best model by mIoU\n    if val_miou > best_miou:\n        best_miou = val_miou\n        torch.save(model.state_dict(), \"deeplab_best_miou.pth\")\n        print(\"  -> New best mIoU; weights saved to deeplab_best_miou.pth\")\n\n    # periodic full checkpoint save\n    if epoch % CHECKPOINT_EVERY == 0:\n        ckpt_path = f\"deeplab_checkpoint_epoch_{epoch}.pth\"\n        torch.save({\n            \"config\": CONFIG,\n            \"epoch\": epoch,\n            \"model_state_dict\": model.state_dict(),\n            \"optimizer_state_dict\": optimizer.state_dict(),\n            \"scheduler_state_dict\": scheduler.state_dict(),\n            \"best_miou\": best_miou,\n            \"history\": history,\n        }, ckpt_path)\n        print(f\"  -> Checkpoint saved to {ckpt_path}\")\n\n# final \"last\" checkpoint\ntorch.save({\n    \"config\": CONFIG,\n    \"epoch\": EPOCHS,\n    \"model_state_dict\": model.state_dict(),\n    \"optimizer_state_dict\": optimizer.state_dict(),\n    \"scheduler_state_dict\": scheduler.state_dict(),\n    \"best_miou\": best_miou,\n    \"history\": history,\n}, \"deeplab_last.pth\")\n\nprint(\"\\nTraining complete. Best mIoU:\", best_miou)\n\n# Store training logs in JSON format\n\noutput_path = Path(\"/kaggle/working/deeplab_results.json\")\n\nresults = {\n    \"config\": CONFIG,\n    \"history\": history,\n}\n\nwith open(output_path, \"w\") as f:\n    json.dump(results, f, indent=2)\n\nprint(\"Saved metrics to:\", output_path)\n\n# Download link for results\nFileLink('/kaggle/working/deeplab_results.json')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-22T14:33:59.707270Z","iopub.execute_input":"2025-11-22T14:33:59.707840Z","iopub.status.idle":"2025-11-22T20:46:52.137960Z","shell.execute_reply.started":"2025-11-22T14:33:59.707815Z","shell.execute_reply":"2025-11-22T20:46:52.136909Z"}},"outputs":[{"name":"stdout","text":"\n===== Epoch 1/40 =====\n[Epoch 1] Step 1/737 - Loss: 0.6450\n[Epoch 1] Step 50/737 - Loss: 0.6377\n[Epoch 1] Step 100/737 - Loss: 0.4635\n[Epoch 1] Step 150/737 - Loss: 0.7103\n[Epoch 1] Step 200/737 - Loss: 0.5733\n[Epoch 1] Step 250/737 - Loss: 0.8020\n[Epoch 1] Step 300/737 - Loss: 0.7949\n[Epoch 1] Step 350/737 - Loss: 0.6793\n[Epoch 1] Step 400/737 - Loss: 0.6238\n[Epoch 1] Step 450/737 - Loss: 0.8973\n[Epoch 1] Step 500/737 - Loss: 0.6295\n[Epoch 1] Step 550/737 - Loss: 0.9504\n[Epoch 1] Step 600/737 - Loss: 0.7980\n[Epoch 1] Step 650/737 - Loss: 0.7801\n[Epoch 1] Step 700/737 - Loss: 0.7992\nEpoch 001 | TrainLoss(step): 0.8234 | TrainLoss(eval): 0.7466 | ValLoss: 0.7847 | Train mIoU: 0.1897 | Val mIoU: 0.1705 | Val Dice: 1.6069 | Val F1: 0.2452 | Val Acc: 0.7593 | LR: 0.000100\n  -> New best mIoU; weights saved to deeplab_best_miou.pth\n\n===== Epoch 2/40 =====\n[Epoch 2] Step 1/737 - Loss: 0.7732\n[Epoch 2] Step 50/737 - Loss: 0.6691\n[Epoch 2] Step 100/737 - Loss: 0.5755\n[Epoch 2] Step 150/737 - Loss: 0.4297\n[Epoch 2] Step 200/737 - Loss: 0.5712\n[Epoch 2] Step 250/737 - Loss: 0.9323\n[Epoch 2] Step 300/737 - Loss: 1.1534\n[Epoch 2] Step 350/737 - Loss: 1.5954\n[Epoch 2] Step 400/737 - Loss: 0.5299\n[Epoch 2] Step 450/737 - Loss: 0.4776\n[Epoch 2] Step 500/737 - Loss: 0.4687\n[Epoch 2] Step 550/737 - Loss: 0.8939\n[Epoch 2] Step 600/737 - Loss: 0.6620\n[Epoch 2] Step 650/737 - Loss: 0.9375\n[Epoch 2] Step 700/737 - Loss: 0.9163\nEpoch 002 | TrainLoss(step): 0.7406 | TrainLoss(eval): 0.6937 | ValLoss: 0.7676 | Train mIoU: 0.2150 | Val mIoU: 0.1926 | Val Dice: 1.8166 | Val F1: 0.2812 | Val Acc: 0.7647 | LR: 0.000100\n  -> New best mIoU; weights saved to deeplab_best_miou.pth\n  -> Checkpoint saved to deeplab_checkpoint_epoch_2.pth\n\n===== Epoch 3/40 =====\n[Epoch 3] Step 1/737 - Loss: 0.8354\n[Epoch 3] Step 50/737 - Loss: 0.6692\n[Epoch 3] Step 100/737 - Loss: 0.7762\n[Epoch 3] Step 150/737 - Loss: 0.5313\n[Epoch 3] Step 200/737 - Loss: 0.7068\n[Epoch 3] Step 250/737 - Loss: 0.5859\n[Epoch 3] Step 300/737 - Loss: 0.7629\n[Epoch 3] Step 350/737 - Loss: 0.5641\n[Epoch 3] Step 400/737 - Loss: 0.6370\n[Epoch 3] Step 450/737 - Loss: 0.6944\n[Epoch 3] Step 500/737 - Loss: 0.4757\n[Epoch 3] Step 550/737 - Loss: 0.7306\n[Epoch 3] Step 600/737 - Loss: 0.5288\n[Epoch 3] Step 650/737 - Loss: 0.7118\n[Epoch 3] Step 700/737 - Loss: 0.8582\nEpoch 003 | TrainLoss(step): 0.6852 | TrainLoss(eval): 0.6039 | ValLoss: 0.7168 | Train mIoU: 0.2530 | Val mIoU: 0.2040 | Val Dice: 1.6481 | Val F1: 0.2911 | Val Acc: 0.7790 | LR: 0.000100\n  -> New best mIoU; weights saved to deeplab_best_miou.pth\n\n===== Epoch 4/40 =====\n[Epoch 4] Step 1/737 - Loss: 0.5153\n[Epoch 4] Step 50/737 - Loss: 0.5151\n[Epoch 4] Step 100/737 - Loss: 0.4269\n[Epoch 4] Step 150/737 - Loss: 0.5464\n[Epoch 4] Step 200/737 - Loss: 0.5045\n[Epoch 4] Step 250/737 - Loss: 0.4770\n[Epoch 4] Step 300/737 - Loss: 0.6216\n[Epoch 4] Step 350/737 - Loss: 0.9068\n[Epoch 4] Step 400/737 - Loss: 0.8044\n[Epoch 4] Step 450/737 - Loss: 0.5886\n[Epoch 4] Step 500/737 - Loss: 0.4358\n[Epoch 4] Step 550/737 - Loss: 0.5843\n[Epoch 4] Step 600/737 - Loss: 0.8004\n[Epoch 4] Step 650/737 - Loss: 0.6291\n[Epoch 4] Step 700/737 - Loss: 0.4532\nEpoch 004 | TrainLoss(step): 0.6416 | TrainLoss(eval): 0.5387 | ValLoss: 0.6827 | Train mIoU: 0.3122 | Val mIoU: 0.2484 | Val Dice: 2.0188 | Val F1: 0.3578 | Val Acc: 0.7885 | LR: 0.000100\n  -> New best mIoU; weights saved to deeplab_best_miou.pth\n  -> Checkpoint saved to deeplab_checkpoint_epoch_4.pth\n\n===== Epoch 5/40 =====\n[Epoch 5] Step 1/737 - Loss: 0.6253\n[Epoch 5] Step 50/737 - Loss: 0.3361\n[Epoch 5] Step 100/737 - Loss: 0.4235\n[Epoch 5] Step 150/737 - Loss: 0.5908\n[Epoch 5] Step 200/737 - Loss: 0.4959\n[Epoch 5] Step 250/737 - Loss: 0.4591\n[Epoch 5] Step 300/737 - Loss: 0.7225\n[Epoch 5] Step 350/737 - Loss: 0.5707\n[Epoch 5] Step 400/737 - Loss: 0.5917\n[Epoch 5] Step 450/737 - Loss: 0.3387\n[Epoch 5] Step 500/737 - Loss: 0.7380\n[Epoch 5] Step 550/737 - Loss: 0.9732\n[Epoch 5] Step 600/737 - Loss: 0.3820\n[Epoch 5] Step 650/737 - Loss: 0.5261\n[Epoch 5] Step 700/737 - Loss: 0.6293\nEpoch 005 | TrainLoss(step): 0.5944 | TrainLoss(eval): 0.5480 | ValLoss: 0.7674 | Train mIoU: 0.3168 | Val mIoU: 0.2363 | Val Dice: 2.2740 | Val F1: 0.3424 | Val Acc: 0.7574 | LR: 0.000100\n\n===== Epoch 6/40 =====\n[Epoch 6] Step 1/737 - Loss: 0.5385\n[Epoch 6] Step 50/737 - Loss: 0.5922\n[Epoch 6] Step 100/737 - Loss: 0.7169\n[Epoch 6] Step 150/737 - Loss: 0.5859\n[Epoch 6] Step 200/737 - Loss: 0.8009\n[Epoch 6] Step 250/737 - Loss: 1.1750\n[Epoch 6] Step 300/737 - Loss: 1.3018\n[Epoch 6] Step 350/737 - Loss: 0.5277\n[Epoch 6] Step 400/737 - Loss: 0.3470\n[Epoch 6] Step 450/737 - Loss: 0.4981\n[Epoch 6] Step 500/737 - Loss: 0.7202\n[Epoch 6] Step 550/737 - Loss: 0.7427\n[Epoch 6] Step 600/737 - Loss: 0.4076\n[Epoch 6] Step 650/737 - Loss: 0.6313\n[Epoch 6] Step 700/737 - Loss: 0.8687\nEpoch 006 | TrainLoss(step): 0.5534 | TrainLoss(eval): 0.4849 | ValLoss: 0.7189 | Train mIoU: 0.3506 | Val mIoU: 0.2506 | Val Dice: 1.9910 | Val F1: 0.3597 | Val Acc: 0.7871 | LR: 0.000100\n  -> New best mIoU; weights saved to deeplab_best_miou.pth\n  -> Checkpoint saved to deeplab_checkpoint_epoch_6.pth\n\n===== Epoch 7/40 =====\n[Epoch 7] Step 1/737 - Loss: 0.3573\n[Epoch 7] Step 50/737 - Loss: 0.6370\n[Epoch 7] Step 100/737 - Loss: 0.4256\n[Epoch 7] Step 150/737 - Loss: 0.4855\n[Epoch 7] Step 200/737 - Loss: 0.8167\n[Epoch 7] Step 250/737 - Loss: 0.9016\n[Epoch 7] Step 300/737 - Loss: 0.4102\n[Epoch 7] Step 350/737 - Loss: 0.5522\n[Epoch 7] Step 400/737 - Loss: 0.5887\n[Epoch 7] Step 450/737 - Loss: 0.7163\n[Epoch 7] Step 500/737 - Loss: 0.3359\n[Epoch 7] Step 550/737 - Loss: 0.5954\n[Epoch 7] Step 600/737 - Loss: 0.3485\n[Epoch 7] Step 650/737 - Loss: 0.4241\n[Epoch 7] Step 700/737 - Loss: 0.3841\nEpoch 007 | TrainLoss(step): 0.5047 | TrainLoss(eval): 0.4384 | ValLoss: 0.7429 | Train mIoU: 0.3955 | Val mIoU: 0.2481 | Val Dice: 2.3446 | Val F1: 0.3614 | Val Acc: 0.7734 | LR: 0.000100\n\n===== Epoch 8/40 =====\n[Epoch 8] Step 1/737 - Loss: 1.2085\n[Epoch 8] Step 50/737 - Loss: 0.3461\n[Epoch 8] Step 100/737 - Loss: 0.3473\n[Epoch 8] Step 150/737 - Loss: 0.3694\n[Epoch 8] Step 200/737 - Loss: 0.3732\n[Epoch 8] Step 250/737 - Loss: 0.4818\n[Epoch 8] Step 300/737 - Loss: 0.4710\n[Epoch 8] Step 350/737 - Loss: 0.2668\n[Epoch 8] Step 400/737 - Loss: 0.3553\n[Epoch 8] Step 450/737 - Loss: 0.3127\n[Epoch 8] Step 500/737 - Loss: 0.5800\n[Epoch 8] Step 550/737 - Loss: 0.4526\n[Epoch 8] Step 600/737 - Loss: 0.2972\n[Epoch 8] Step 650/737 - Loss: 0.4280\n[Epoch 8] Step 700/737 - Loss: 0.3449\nEpoch 008 | TrainLoss(step): 0.4684 | TrainLoss(eval): 0.3771 | ValLoss: 0.7028 | Train mIoU: 0.4166 | Val mIoU: 0.2605 | Val Dice: 2.2953 | Val F1: 0.3691 | Val Acc: 0.7921 | LR: 0.000050\n  -> New best mIoU; weights saved to deeplab_best_miou.pth\n  -> Checkpoint saved to deeplab_checkpoint_epoch_8.pth\n\n===== Epoch 9/40 =====\n[Epoch 9] Step 1/737 - Loss: 0.3771\n[Epoch 9] Step 50/737 - Loss: 0.7571\n[Epoch 9] Step 100/737 - Loss: 0.6104\n[Epoch 9] Step 150/737 - Loss: 0.8746\n[Epoch 9] Step 200/737 - Loss: 0.5632\n[Epoch 9] Step 250/737 - Loss: 0.1976\n[Epoch 9] Step 300/737 - Loss: 0.3045\n[Epoch 9] Step 350/737 - Loss: 0.6013\n[Epoch 9] Step 400/737 - Loss: 0.2867\n[Epoch 9] Step 450/737 - Loss: 0.3623\n[Epoch 9] Step 500/737 - Loss: 0.4047\n[Epoch 9] Step 550/737 - Loss: 0.4764\n[Epoch 9] Step 600/737 - Loss: 0.2086\n[Epoch 9] Step 650/737 - Loss: 0.2034\n[Epoch 9] Step 700/737 - Loss: 0.3014\nEpoch 009 | TrainLoss(step): 0.3841 | TrainLoss(eval): 0.2891 | ValLoss: 0.7015 | Train mIoU: 0.5183 | Val mIoU: 0.2928 | Val Dice: 2.5879 | Val F1: 0.4165 | Val Acc: 0.7952 | LR: 0.000050\n  -> New best mIoU; weights saved to deeplab_best_miou.pth\n\n===== Epoch 10/40 =====\n[Epoch 10] Step 1/737 - Loss: 0.2619\n[Epoch 10] Step 50/737 - Loss: 0.2963\n[Epoch 10] Step 100/737 - Loss: 0.3046\n[Epoch 10] Step 150/737 - Loss: 0.2995\n[Epoch 10] Step 200/737 - Loss: 0.3466\n[Epoch 10] Step 250/737 - Loss: 0.3431\n[Epoch 10] Step 300/737 - Loss: 0.5161\n[Epoch 10] Step 350/737 - Loss: 0.3836\n[Epoch 10] Step 400/737 - Loss: 0.1949\n[Epoch 10] Step 450/737 - Loss: 0.2636\n[Epoch 10] Step 500/737 - Loss: 0.2873\n[Epoch 10] Step 550/737 - Loss: 0.2823\n[Epoch 10] Step 600/737 - Loss: 0.4051\n[Epoch 10] Step 650/737 - Loss: 0.2374\n[Epoch 10] Step 700/737 - Loss: 0.2460\nEpoch 010 | TrainLoss(step): 0.3351 | TrainLoss(eval): 0.2612 | ValLoss: 0.7305 | Train mIoU: 0.5450 | Val mIoU: 0.2906 | Val Dice: 2.5695 | Val F1: 0.4165 | Val Acc: 0.7925 | LR: 0.000050\n  -> Checkpoint saved to deeplab_checkpoint_epoch_10.pth\n\n===== Epoch 11/40 =====\n[Epoch 11] Step 1/737 - Loss: 0.2881\n[Epoch 11] Step 50/737 - Loss: 0.2238\n[Epoch 11] Step 100/737 - Loss: 0.2304\n[Epoch 11] Step 150/737 - Loss: 0.3682\n[Epoch 11] Step 200/737 - Loss: 0.3144\n[Epoch 11] Step 250/737 - Loss: 0.1543\n[Epoch 11] Step 300/737 - Loss: 0.2015\n[Epoch 11] Step 350/737 - Loss: 0.3362\n[Epoch 11] Step 400/737 - Loss: 0.1891\n[Epoch 11] Step 450/737 - Loss: 0.3799\n[Epoch 11] Step 500/737 - Loss: 0.4038\n[Epoch 11] Step 550/737 - Loss: 0.3649\n[Epoch 11] Step 600/737 - Loss: 0.3382\n[Epoch 11] Step 650/737 - Loss: 0.3067\n[Epoch 11] Step 700/737 - Loss: 0.1810\nEpoch 011 | TrainLoss(step): 0.3067 | TrainLoss(eval): 0.2335 | ValLoss: 0.7330 | Train mIoU: 0.5766 | Val mIoU: 0.3041 | Val Dice: 2.5731 | Val F1: 0.4375 | Val Acc: 0.7948 | LR: 0.000050\n  -> New best mIoU; weights saved to deeplab_best_miou.pth\n\n===== Epoch 12/40 =====\n[Epoch 12] Step 1/737 - Loss: 0.1997\n[Epoch 12] Step 50/737 - Loss: 0.2119\n[Epoch 12] Step 100/737 - Loss: 0.1775\n[Epoch 12] Step 150/737 - Loss: 0.1686\n[Epoch 12] Step 200/737 - Loss: 0.3194\n[Epoch 12] Step 250/737 - Loss: 0.2367\n[Epoch 12] Step 300/737 - Loss: 0.2651\n[Epoch 12] Step 350/737 - Loss: 0.5126\n[Epoch 12] Step 400/737 - Loss: 0.1347\n[Epoch 12] Step 450/737 - Loss: 0.1673\n[Epoch 12] Step 500/737 - Loss: 0.1823\n[Epoch 12] Step 550/737 - Loss: 0.2271\n[Epoch 12] Step 600/737 - Loss: 0.2670\n[Epoch 12] Step 650/737 - Loss: 0.5076\n[Epoch 12] Step 700/737 - Loss: 0.2548\nEpoch 012 | TrainLoss(step): 0.2777 | TrainLoss(eval): 0.2184 | ValLoss: 0.7394 | Train mIoU: 0.5966 | Val mIoU: 0.3038 | Val Dice: 2.8321 | Val F1: 0.4344 | Val Acc: 0.7895 | LR: 0.000025\n  -> Checkpoint saved to deeplab_checkpoint_epoch_12.pth\n\n===== Epoch 13/40 =====\n[Epoch 13] Step 1/737 - Loss: 0.2283\n[Epoch 13] Step 50/737 - Loss: 0.2721\n[Epoch 13] Step 100/737 - Loss: 0.1195\n[Epoch 13] Step 150/737 - Loss: 0.1874\n[Epoch 13] Step 200/737 - Loss: 0.2340\n[Epoch 13] Step 250/737 - Loss: 0.2075\n[Epoch 13] Step 300/737 - Loss: 0.2013\n[Epoch 13] Step 350/737 - Loss: 0.1724\n[Epoch 13] Step 400/737 - Loss: 0.1305\n[Epoch 13] Step 450/737 - Loss: 0.2761\n[Epoch 13] Step 500/737 - Loss: 0.2241\n[Epoch 13] Step 550/737 - Loss: 0.2646\n[Epoch 13] Step 600/737 - Loss: 0.2155\n[Epoch 13] Step 650/737 - Loss: 0.3022\n[Epoch 13] Step 700/737 - Loss: 0.3198\nEpoch 013 | TrainLoss(step): 0.2394 | TrainLoss(eval): 0.1898 | ValLoss: 0.7433 | Train mIoU: 0.6244 | Val mIoU: 0.3070 | Val Dice: 2.7265 | Val F1: 0.4402 | Val Acc: 0.7939 | LR: 0.000025\n  -> New best mIoU; weights saved to deeplab_best_miou.pth\n\n===== Epoch 14/40 =====\n[Epoch 14] Step 1/737 - Loss: 0.1502\n[Epoch 14] Step 50/737 - Loss: 0.2461\n[Epoch 14] Step 100/737 - Loss: 0.3476\n[Epoch 14] Step 150/737 - Loss: 0.2424\n[Epoch 14] Step 200/737 - Loss: 0.3256\n[Epoch 14] Step 250/737 - Loss: 0.1399\n[Epoch 14] Step 300/737 - Loss: 0.1842\n[Epoch 14] Step 350/737 - Loss: 0.2038\n[Epoch 14] Step 400/737 - Loss: 0.1547\n[Epoch 14] Step 450/737 - Loss: 0.1873\n[Epoch 14] Step 500/737 - Loss: 0.1966\n[Epoch 14] Step 550/737 - Loss: 0.1962\n[Epoch 14] Step 600/737 - Loss: 0.2511\n[Epoch 14] Step 650/737 - Loss: 0.1820\n[Epoch 14] Step 700/737 - Loss: 0.2399\nEpoch 014 | TrainLoss(step): 0.2200 | TrainLoss(eval): 0.1736 | ValLoss: 0.7742 | Train mIoU: 0.6470 | Val mIoU: 0.3056 | Val Dice: 2.6461 | Val F1: 0.4381 | Val Acc: 0.7961 | LR: 0.000025\n  -> Checkpoint saved to deeplab_checkpoint_epoch_14.pth\n\n===== Epoch 15/40 =====\n[Epoch 15] Step 1/737 - Loss: 0.2391\n[Epoch 15] Step 50/737 - Loss: 0.2219\n[Epoch 15] Step 100/737 - Loss: 0.1290\n[Epoch 15] Step 150/737 - Loss: 0.1445\n[Epoch 15] Step 200/737 - Loss: 0.2221\n[Epoch 15] Step 250/737 - Loss: 0.1244\n[Epoch 15] Step 300/737 - Loss: 0.1256\n[Epoch 15] Step 350/737 - Loss: 0.1718\n[Epoch 15] Step 400/737 - Loss: 0.3908\n[Epoch 15] Step 450/737 - Loss: 0.1838\n[Epoch 15] Step 500/737 - Loss: 0.2237\n[Epoch 15] Step 550/737 - Loss: 0.3383\n[Epoch 15] Step 600/737 - Loss: 0.1618\n[Epoch 15] Step 650/737 - Loss: 0.1626\n[Epoch 15] Step 700/737 - Loss: 0.1524\nEpoch 015 | TrainLoss(step): 0.2026 | TrainLoss(eval): 0.1678 | ValLoss: 0.7736 | Train mIoU: 0.6578 | Val mIoU: 0.3129 | Val Dice: 2.7599 | Val F1: 0.4492 | Val Acc: 0.7921 | LR: 0.000025\n  -> New best mIoU; weights saved to deeplab_best_miou.pth\n\n===== Epoch 16/40 =====\n[Epoch 16] Step 1/737 - Loss: 0.1562\n[Epoch 16] Step 50/737 - Loss: 0.2020\n[Epoch 16] Step 100/737 - Loss: 0.1491\n[Epoch 16] Step 150/737 - Loss: 0.1777\n[Epoch 16] Step 200/737 - Loss: 0.1911\n[Epoch 16] Step 250/737 - Loss: 0.2595\n[Epoch 16] Step 300/737 - Loss: 0.1099\n[Epoch 16] Step 350/737 - Loss: 0.0802\n[Epoch 16] Step 400/737 - Loss: 0.1457\n[Epoch 16] Step 450/737 - Loss: 0.3026\n[Epoch 16] Step 500/737 - Loss: 0.0737\n[Epoch 16] Step 550/737 - Loss: 0.2236\n[Epoch 16] Step 600/737 - Loss: 0.2324\n[Epoch 16] Step 650/737 - Loss: 0.2219\n[Epoch 16] Step 700/737 - Loss: 0.1889\nEpoch 016 | TrainLoss(step): 0.1908 | TrainLoss(eval): 0.1553 | ValLoss: 0.8118 | Train mIoU: 0.6675 | Val mIoU: 0.3048 | Val Dice: 2.5943 | Val F1: 0.4378 | Val Acc: 0.7953 | LR: 0.000013\n  -> Checkpoint saved to deeplab_checkpoint_epoch_16.pth\n\n===== Epoch 17/40 =====\n[Epoch 17] Step 1/737 - Loss: 0.1853\n[Epoch 17] Step 50/737 - Loss: 0.1716\n[Epoch 17] Step 100/737 - Loss: 0.1619\n[Epoch 17] Step 150/737 - Loss: 0.1460\n[Epoch 17] Step 200/737 - Loss: 0.1873\n[Epoch 17] Step 250/737 - Loss: 0.1764\n[Epoch 17] Step 300/737 - Loss: 0.1238\n[Epoch 17] Step 350/737 - Loss: 0.1791\n[Epoch 17] Step 400/737 - Loss: 0.1434\n[Epoch 17] Step 450/737 - Loss: 0.2133\n[Epoch 17] Step 500/737 - Loss: 0.1908\n[Epoch 17] Step 550/737 - Loss: 0.1407\n[Epoch 17] Step 600/737 - Loss: 0.0817\n[Epoch 17] Step 650/737 - Loss: 0.2223\n[Epoch 17] Step 700/737 - Loss: 0.1988\nEpoch 017 | TrainLoss(step): 0.1758 | TrainLoss(eval): 0.1431 | ValLoss: 0.8454 | Train mIoU: 0.6878 | Val mIoU: 0.3009 | Val Dice: 2.5649 | Val F1: 0.4319 | Val Acc: 0.7982 | LR: 0.000013\n\n===== Epoch 18/40 =====\n[Epoch 18] Step 1/737 - Loss: 0.1416\n[Epoch 18] Step 50/737 - Loss: 0.1563\n[Epoch 18] Step 100/737 - Loss: 0.1817\n[Epoch 18] Step 150/737 - Loss: 0.0873\n[Epoch 18] Step 200/737 - Loss: 0.1752\n[Epoch 18] Step 250/737 - Loss: 0.1839\n[Epoch 18] Step 300/737 - Loss: 0.1164\n[Epoch 18] Step 350/737 - Loss: 0.1976\n[Epoch 18] Step 400/737 - Loss: 0.1262\n[Epoch 18] Step 450/737 - Loss: 0.1008\n[Epoch 18] Step 500/737 - Loss: 0.1796\n[Epoch 18] Step 550/737 - Loss: 0.1490\n[Epoch 18] Step 600/737 - Loss: 0.1089\n[Epoch 18] Step 650/737 - Loss: 0.1837\n[Epoch 18] Step 700/737 - Loss: 0.1408\nEpoch 018 | TrainLoss(step): 0.1655 | TrainLoss(eval): 0.1372 | ValLoss: 0.8312 | Train mIoU: 0.6955 | Val mIoU: 0.3111 | Val Dice: 2.7342 | Val F1: 0.4459 | Val Acc: 0.7944 | LR: 0.000013\n  -> Checkpoint saved to deeplab_checkpoint_epoch_18.pth\n\n===== Epoch 19/40 =====\n[Epoch 19] Step 1/737 - Loss: 0.0972\n[Epoch 19] Step 50/737 - Loss: 0.1534\n[Epoch 19] Step 100/737 - Loss: 0.1577\n[Epoch 19] Step 150/737 - Loss: 0.1393\n[Epoch 19] Step 200/737 - Loss: 0.1460\n[Epoch 19] Step 250/737 - Loss: 0.1644\n[Epoch 19] Step 300/737 - Loss: 0.0983\n[Epoch 19] Step 350/737 - Loss: 0.1941\n[Epoch 19] Step 400/737 - Loss: 0.1120\n[Epoch 19] Step 450/737 - Loss: 0.1817\n[Epoch 19] Step 500/737 - Loss: 0.1219\n[Epoch 19] Step 550/737 - Loss: 0.1212\n[Epoch 19] Step 600/737 - Loss: 0.1683\n[Epoch 19] Step 650/737 - Loss: 0.1190\n[Epoch 19] Step 700/737 - Loss: 0.1084\nEpoch 019 | TrainLoss(step): 0.1589 | TrainLoss(eval): 0.1313 | ValLoss: 0.8608 | Train mIoU: 0.7016 | Val mIoU: 0.3031 | Val Dice: 2.6216 | Val F1: 0.4357 | Val Acc: 0.7957 | LR: 0.000013\n\n===== Epoch 20/40 =====\n[Epoch 20] Step 1/737 - Loss: 0.2187\n[Epoch 20] Step 50/737 - Loss: 0.1072\n[Epoch 20] Step 100/737 - Loss: 0.1362\n[Epoch 20] Step 150/737 - Loss: 0.1044\n[Epoch 20] Step 200/737 - Loss: 0.1242\n[Epoch 20] Step 250/737 - Loss: 0.2109\n[Epoch 20] Step 300/737 - Loss: 0.3162\n[Epoch 20] Step 350/737 - Loss: 0.1114\n[Epoch 20] Step 400/737 - Loss: 0.1735\n[Epoch 20] Step 450/737 - Loss: 0.3037\n[Epoch 20] Step 500/737 - Loss: 0.2786\n[Epoch 20] Step 550/737 - Loss: 0.1155\n[Epoch 20] Step 600/737 - Loss: 0.1573\n[Epoch 20] Step 650/737 - Loss: 0.1303\n[Epoch 20] Step 700/737 - Loss: 0.1634\nEpoch 020 | TrainLoss(step): 0.1553 | TrainLoss(eval): 0.1277 | ValLoss: 0.8604 | Train mIoU: 0.7091 | Val mIoU: 0.3037 | Val Dice: 2.6678 | Val F1: 0.4368 | Val Acc: 0.7945 | LR: 0.000006\n  -> Checkpoint saved to deeplab_checkpoint_epoch_20.pth\n\n===== Epoch 21/40 =====\n[Epoch 21] Step 1/737 - Loss: 0.1143\n[Epoch 21] Step 50/737 - Loss: 0.1551\n[Epoch 21] Step 100/737 - Loss: 0.1705\n[Epoch 21] Step 150/737 - Loss: 0.1081\n[Epoch 21] Step 200/737 - Loss: 0.0776\n[Epoch 21] Step 250/737 - Loss: 0.0601\n[Epoch 21] Step 300/737 - Loss: 0.2455\n[Epoch 21] Step 350/737 - Loss: 0.1380\n[Epoch 21] Step 400/737 - Loss: 0.1031\n[Epoch 21] Step 450/737 - Loss: 0.1193\n[Epoch 21] Step 500/737 - Loss: 0.2513\n[Epoch 21] Step 550/737 - Loss: 0.1391\n[Epoch 21] Step 600/737 - Loss: 0.0973\n[Epoch 21] Step 650/737 - Loss: 0.1938\n[Epoch 21] Step 700/737 - Loss: 0.1530\nEpoch 021 | TrainLoss(step): 0.1476 | TrainLoss(eval): 0.1227 | ValLoss: 0.8499 | Train mIoU: 0.7177 | Val mIoU: 0.3066 | Val Dice: 2.6882 | Val F1: 0.4404 | Val Acc: 0.7927 | LR: 0.000006\n\n===== Epoch 22/40 =====\n[Epoch 22] Step 1/737 - Loss: 0.1113\n[Epoch 22] Step 50/737 - Loss: 0.0901\n[Epoch 22] Step 100/737 - Loss: 0.1032\n[Epoch 22] Step 150/737 - Loss: 0.1035\n[Epoch 22] Step 200/737 - Loss: 0.1081\n[Epoch 22] Step 250/737 - Loss: 0.1405\n[Epoch 22] Step 300/737 - Loss: 0.0909\n[Epoch 22] Step 350/737 - Loss: 0.1539\n[Epoch 22] Step 400/737 - Loss: 0.1477\n[Epoch 22] Step 450/737 - Loss: 0.2396\n[Epoch 22] Step 500/737 - Loss: 0.1986\n[Epoch 22] Step 550/737 - Loss: 0.1210\n[Epoch 22] Step 600/737 - Loss: 0.1489\n[Epoch 22] Step 650/737 - Loss: 0.2464\n[Epoch 22] Step 700/737 - Loss: 0.1914\nEpoch 022 | TrainLoss(step): 0.1445 | TrainLoss(eval): 0.1200 | ValLoss: 0.8894 | Train mIoU: 0.7208 | Val mIoU: 0.2995 | Val Dice: 2.6450 | Val F1: 0.4305 | Val Acc: 0.7946 | LR: 0.000006\n  -> Checkpoint saved to deeplab_checkpoint_epoch_22.pth\n\n===== Epoch 23/40 =====\n[Epoch 23] Step 1/737 - Loss: 0.1176\n[Epoch 23] Step 50/737 - Loss: 0.1563\n[Epoch 23] Step 100/737 - Loss: 0.1476\n[Epoch 23] Step 150/737 - Loss: 0.2703\n[Epoch 23] Step 200/737 - Loss: 0.0936\n[Epoch 23] Step 250/737 - Loss: 0.1359\n[Epoch 23] Step 300/737 - Loss: 0.2433\n[Epoch 23] Step 350/737 - Loss: 0.0997\n[Epoch 23] Step 400/737 - Loss: 0.1863\n[Epoch 23] Step 450/737 - Loss: 0.1433\n[Epoch 23] Step 500/737 - Loss: 0.1584\n[Epoch 23] Step 550/737 - Loss: 0.1314\n[Epoch 23] Step 600/737 - Loss: 0.0848\n[Epoch 23] Step 650/737 - Loss: 0.0929\n[Epoch 23] Step 700/737 - Loss: 0.1540\nEpoch 023 | TrainLoss(step): 0.1399 | TrainLoss(eval): 0.1156 | ValLoss: 0.8708 | Train mIoU: 0.7302 | Val mIoU: 0.3105 | Val Dice: 2.6791 | Val F1: 0.4447 | Val Acc: 0.7943 | LR: 0.000006\n\n===== Epoch 24/40 =====\n[Epoch 24] Step 1/737 - Loss: 0.1250\n[Epoch 24] Step 50/737 - Loss: 0.0868\n[Epoch 24] Step 100/737 - Loss: 0.1038\n[Epoch 24] Step 150/737 - Loss: 0.1223\n[Epoch 24] Step 200/737 - Loss: 0.1759\n[Epoch 24] Step 250/737 - Loss: 0.1559\n[Epoch 24] Step 300/737 - Loss: 0.2197\n[Epoch 24] Step 350/737 - Loss: 0.1241\n[Epoch 24] Step 400/737 - Loss: 0.1215\n[Epoch 24] Step 450/737 - Loss: 0.1449\n[Epoch 24] Step 500/737 - Loss: 0.1418\n[Epoch 24] Step 550/737 - Loss: 0.2775\n[Epoch 24] Step 600/737 - Loss: 0.1345\n[Epoch 24] Step 650/737 - Loss: 0.0630\n[Epoch 24] Step 700/737 - Loss: 0.1212\nEpoch 024 | TrainLoss(step): 0.1377 | TrainLoss(eval): 0.1151 | ValLoss: 0.8964 | Train mIoU: 0.7241 | Val mIoU: 0.2981 | Val Dice: 2.6685 | Val F1: 0.4301 | Val Acc: 0.7922 | LR: 0.000003\n  -> Checkpoint saved to deeplab_checkpoint_epoch_24.pth\n\n===== Epoch 25/40 =====\n[Epoch 25] Step 1/737 - Loss: 0.1238\n[Epoch 25] Step 50/737 - Loss: 0.1474\n[Epoch 25] Step 100/737 - Loss: 0.2482\n[Epoch 25] Step 150/737 - Loss: 0.1395\n[Epoch 25] Step 200/737 - Loss: 0.1219\n[Epoch 25] Step 250/737 - Loss: 0.1586\n[Epoch 25] Step 300/737 - Loss: 0.2028\n[Epoch 25] Step 350/737 - Loss: 0.1318\n[Epoch 25] Step 400/737 - Loss: 0.1589\n[Epoch 25] Step 450/737 - Loss: 0.1128\n[Epoch 25] Step 500/737 - Loss: 0.1241\n[Epoch 25] Step 550/737 - Loss: 0.1345\n[Epoch 25] Step 600/737 - Loss: 0.1533\n[Epoch 25] Step 650/737 - Loss: 0.0724\n[Epoch 25] Step 700/737 - Loss: 0.1782\nEpoch 025 | TrainLoss(step): 0.1340 | TrainLoss(eval): 0.1117 | ValLoss: 0.8795 | Train mIoU: 0.7342 | Val mIoU: 0.3041 | Val Dice: 2.7049 | Val F1: 0.4375 | Val Acc: 0.7921 | LR: 0.000003\n\n===== Epoch 26/40 =====\n[Epoch 26] Step 1/737 - Loss: 0.0974\n[Epoch 26] Step 50/737 - Loss: 0.0878\n[Epoch 26] Step 100/737 - Loss: 0.1330\n[Epoch 26] Step 150/737 - Loss: 0.1483\n[Epoch 26] Step 200/737 - Loss: 0.1838\n[Epoch 26] Step 250/737 - Loss: 0.0921\n[Epoch 26] Step 300/737 - Loss: 0.1392\n[Epoch 26] Step 350/737 - Loss: 0.1055\n[Epoch 26] Step 400/737 - Loss: 0.1754\n[Epoch 26] Step 450/737 - Loss: 0.2515\n[Epoch 26] Step 500/737 - Loss: 0.1126\n[Epoch 26] Step 550/737 - Loss: 0.1087\n[Epoch 26] Step 600/737 - Loss: 0.1454\n[Epoch 26] Step 650/737 - Loss: 0.1680\n[Epoch 26] Step 700/737 - Loss: 0.2344\nEpoch 026 | TrainLoss(step): 0.1323 | TrainLoss(eval): 0.1118 | ValLoss: 0.8872 | Train mIoU: 0.7318 | Val mIoU: 0.3021 | Val Dice: 2.6877 | Val F1: 0.4355 | Val Acc: 0.7921 | LR: 0.000003\n  -> Checkpoint saved to deeplab_checkpoint_epoch_26.pth\n\n===== Epoch 27/40 =====\n[Epoch 27] Step 1/737 - Loss: 0.1631\n[Epoch 27] Step 50/737 - Loss: 0.1759\n[Epoch 27] Step 100/737 - Loss: 0.1192\n[Epoch 27] Step 150/737 - Loss: 0.1399\n[Epoch 27] Step 200/737 - Loss: 0.0355\n[Epoch 27] Step 250/737 - Loss: 0.1062\n[Epoch 27] Step 300/737 - Loss: 0.1010\n[Epoch 27] Step 350/737 - Loss: 0.0813\n[Epoch 27] Step 400/737 - Loss: 0.1275\n[Epoch 27] Step 450/737 - Loss: 0.2112\n[Epoch 27] Step 500/737 - Loss: 0.1253\n[Epoch 27] Step 550/737 - Loss: 0.1911\n[Epoch 27] Step 600/737 - Loss: 0.1687\n[Epoch 27] Step 650/737 - Loss: 0.1550\n[Epoch 27] Step 700/737 - Loss: 0.1920\nEpoch 027 | TrainLoss(step): 0.1313 | TrainLoss(eval): 0.1083 | ValLoss: 0.9015 | Train mIoU: 0.7400 | Val mIoU: 0.3034 | Val Dice: 2.6538 | Val F1: 0.4357 | Val Acc: 0.7944 | LR: 0.000003\n\n===== Epoch 28/40 =====\n[Epoch 28] Step 1/737 - Loss: 0.1418\n[Epoch 28] Step 50/737 - Loss: 0.1429\n[Epoch 28] Step 100/737 - Loss: 0.0851\n[Epoch 28] Step 150/737 - Loss: 0.0975\n[Epoch 28] Step 200/737 - Loss: 0.0929\n[Epoch 28] Step 250/737 - Loss: 0.1499\n[Epoch 28] Step 300/737 - Loss: 0.1737\n[Epoch 28] Step 350/737 - Loss: 0.0984\n[Epoch 28] Step 400/737 - Loss: 0.1471\n[Epoch 28] Step 450/737 - Loss: 0.1392\n[Epoch 28] Step 500/737 - Loss: 0.1171\n[Epoch 28] Step 550/737 - Loss: 0.1536\n[Epoch 28] Step 600/737 - Loss: 0.1130\n[Epoch 28] Step 650/737 - Loss: 0.1252\n[Epoch 28] Step 700/737 - Loss: 0.1199\nEpoch 028 | TrainLoss(step): 0.1301 | TrainLoss(eval): 0.1088 | ValLoss: 0.9007 | Train mIoU: 0.7345 | Val mIoU: 0.3022 | Val Dice: 2.6524 | Val F1: 0.4348 | Val Acc: 0.7946 | LR: 0.000002\n  -> Checkpoint saved to deeplab_checkpoint_epoch_28.pth\n\n===== Epoch 29/40 =====\n[Epoch 29] Step 1/737 - Loss: 0.1098\n[Epoch 29] Step 50/737 - Loss: 0.0717\n[Epoch 29] Step 100/737 - Loss: 0.1003\n[Epoch 29] Step 150/737 - Loss: 0.1455\n[Epoch 29] Step 200/737 - Loss: 0.1628\n[Epoch 29] Step 250/737 - Loss: 0.1614\n[Epoch 29] Step 300/737 - Loss: 0.0915\n[Epoch 29] Step 350/737 - Loss: 0.1004\n[Epoch 29] Step 400/737 - Loss: 0.1173\n[Epoch 29] Step 450/737 - Loss: 0.1692\n[Epoch 29] Step 500/737 - Loss: 0.0678\n[Epoch 29] Step 550/737 - Loss: 0.1622\n[Epoch 29] Step 600/737 - Loss: 0.1266\n[Epoch 29] Step 650/737 - Loss: 0.1118\n[Epoch 29] Step 700/737 - Loss: 0.1862\nEpoch 029 | TrainLoss(step): 0.1276 | TrainLoss(eval): 0.1080 | ValLoss: 0.9115 | Train mIoU: 0.7408 | Val mIoU: 0.3041 | Val Dice: 2.6113 | Val F1: 0.4376 | Val Acc: 0.7951 | LR: 0.000002\n\n===== Epoch 30/40 =====\n[Epoch 30] Step 1/737 - Loss: 0.1339\n[Epoch 30] Step 50/737 - Loss: 0.1339\n[Epoch 30] Step 100/737 - Loss: 0.1140\n[Epoch 30] Step 150/737 - Loss: 0.1089\n[Epoch 30] Step 200/737 - Loss: 0.1021\n[Epoch 30] Step 250/737 - Loss: 0.1602\n[Epoch 30] Step 300/737 - Loss: 0.0821\n[Epoch 30] Step 350/737 - Loss: 0.1321\n[Epoch 30] Step 400/737 - Loss: 0.1135\n[Epoch 30] Step 450/737 - Loss: 0.1294\n[Epoch 30] Step 500/737 - Loss: 0.1559\n[Epoch 30] Step 550/737 - Loss: 0.0886\n[Epoch 30] Step 600/737 - Loss: 0.1292\n[Epoch 30] Step 650/737 - Loss: 0.2161\n[Epoch 30] Step 700/737 - Loss: 0.0922\nEpoch 030 | TrainLoss(step): 0.1258 | TrainLoss(eval): 0.1064 | ValLoss: 0.9003 | Train mIoU: 0.7430 | Val mIoU: 0.3023 | Val Dice: 2.6595 | Val F1: 0.4354 | Val Acc: 0.7943 | LR: 0.000002\n  -> Checkpoint saved to deeplab_checkpoint_epoch_30.pth\n\n===== Epoch 31/40 =====\n[Epoch 31] Step 1/737 - Loss: 0.1384\n[Epoch 31] Step 50/737 - Loss: 0.2031\n[Epoch 31] Step 100/737 - Loss: 0.1360\n[Epoch 31] Step 150/737 - Loss: 0.1160\n[Epoch 31] Step 200/737 - Loss: 0.1351\n[Epoch 31] Step 250/737 - Loss: 0.1186\n[Epoch 31] Step 300/737 - Loss: 0.1428\n[Epoch 31] Step 350/737 - Loss: 0.0768\n[Epoch 31] Step 400/737 - Loss: 0.1188\n[Epoch 31] Step 450/737 - Loss: 0.0812\n[Epoch 31] Step 500/737 - Loss: 0.2396\n[Epoch 31] Step 550/737 - Loss: 0.1491\n[Epoch 31] Step 600/737 - Loss: 0.1364\n[Epoch 31] Step 650/737 - Loss: 0.0852\n[Epoch 31] Step 700/737 - Loss: 0.1348\nEpoch 031 | TrainLoss(step): 0.1259 | TrainLoss(eval): 0.1072 | ValLoss: 0.9057 | Train mIoU: 0.7423 | Val mIoU: 0.3061 | Val Dice: 2.6757 | Val F1: 0.4411 | Val Acc: 0.7925 | LR: 0.000002\n\n===== Epoch 32/40 =====\n[Epoch 32] Step 1/737 - Loss: 0.1363\n[Epoch 32] Step 50/737 - Loss: 0.1721\n[Epoch 32] Step 100/737 - Loss: 0.1351\n[Epoch 32] Step 150/737 - Loss: 0.1371\n[Epoch 32] Step 200/737 - Loss: 0.1412\n[Epoch 32] Step 250/737 - Loss: 0.0763\n[Epoch 32] Step 300/737 - Loss: 0.0775\n[Epoch 32] Step 350/737 - Loss: 0.1503\n[Epoch 32] Step 400/737 - Loss: 0.1011\n[Epoch 32] Step 450/737 - Loss: 0.0693\n[Epoch 32] Step 500/737 - Loss: 0.1137\n[Epoch 32] Step 550/737 - Loss: 0.0828\n[Epoch 32] Step 600/737 - Loss: 0.1108\n[Epoch 32] Step 650/737 - Loss: 0.0907\n[Epoch 32] Step 700/737 - Loss: 0.0867\nEpoch 032 | TrainLoss(step): 0.1256 | TrainLoss(eval): 0.1061 | ValLoss: 0.9145 | Train mIoU: 0.7426 | Val mIoU: 0.3009 | Val Dice: 2.6355 | Val F1: 0.4327 | Val Acc: 0.7948 | LR: 0.000001\n  -> Checkpoint saved to deeplab_checkpoint_epoch_32.pth\n\n===== Epoch 33/40 =====\n[Epoch 33] Step 1/737 - Loss: 0.1485\n[Epoch 33] Step 50/737 - Loss: 0.0624\n[Epoch 33] Step 100/737 - Loss: 0.1188\n[Epoch 33] Step 150/737 - Loss: 0.1221\n[Epoch 33] Step 200/737 - Loss: 0.0833\n[Epoch 33] Step 250/737 - Loss: 0.1305\n[Epoch 33] Step 300/737 - Loss: 0.0711\n[Epoch 33] Step 350/737 - Loss: 0.0500\n[Epoch 33] Step 400/737 - Loss: 0.1320\n[Epoch 33] Step 450/737 - Loss: 0.1707\n[Epoch 33] Step 500/737 - Loss: 0.1801\n[Epoch 33] Step 550/737 - Loss: 0.1637\n[Epoch 33] Step 600/737 - Loss: 0.1333\n[Epoch 33] Step 650/737 - Loss: 0.1033\n[Epoch 33] Step 700/737 - Loss: 0.1160\nEpoch 033 | TrainLoss(step): 0.1247 | TrainLoss(eval): 0.1058 | ValLoss: 0.8981 | Train mIoU: 0.7434 | Val mIoU: 0.3033 | Val Dice: 2.7098 | Val F1: 0.4373 | Val Acc: 0.7907 | LR: 0.000001\n\n===== Epoch 34/40 =====\n[Epoch 34] Step 1/737 - Loss: 0.1560\n[Epoch 34] Step 50/737 - Loss: 0.1197\n[Epoch 34] Step 100/737 - Loss: 0.1171\n[Epoch 34] Step 150/737 - Loss: 0.1150\n[Epoch 34] Step 200/737 - Loss: 0.1084\n[Epoch 34] Step 250/737 - Loss: 0.1011\n[Epoch 34] Step 300/737 - Loss: 0.0940\n[Epoch 34] Step 350/737 - Loss: 0.1199\n[Epoch 34] Step 400/737 - Loss: 0.1548\n[Epoch 34] Step 450/737 - Loss: 0.2648\n[Epoch 34] Step 500/737 - Loss: 0.0617\n[Epoch 34] Step 550/737 - Loss: 0.1041\n[Epoch 34] Step 600/737 - Loss: 0.1090\n[Epoch 34] Step 650/737 - Loss: 0.0809\n[Epoch 34] Step 700/737 - Loss: 0.1587\nEpoch 034 | TrainLoss(step): 0.1245 | TrainLoss(eval): 0.1050 | ValLoss: 0.9117 | Train mIoU: 0.7429 | Val mIoU: 0.2993 | Val Dice: 2.6680 | Val F1: 0.4314 | Val Acc: 0.7937 | LR: 0.000001\n  -> Checkpoint saved to deeplab_checkpoint_epoch_34.pth\n\n===== Epoch 35/40 =====\n[Epoch 35] Step 1/737 - Loss: 0.1969\n[Epoch 35] Step 50/737 - Loss: 0.1165\n[Epoch 35] Step 100/737 - Loss: 0.1061\n[Epoch 35] Step 150/737 - Loss: 0.1699\n[Epoch 35] Step 200/737 - Loss: 0.1744\n[Epoch 35] Step 250/737 - Loss: 0.0897\n[Epoch 35] Step 300/737 - Loss: 0.1113\n[Epoch 35] Step 350/737 - Loss: 0.0897\n[Epoch 35] Step 400/737 - Loss: 0.1973\n[Epoch 35] Step 450/737 - Loss: 0.1504\n[Epoch 35] Step 500/737 - Loss: 0.1831\n[Epoch 35] Step 550/737 - Loss: 0.1402\n[Epoch 35] Step 600/737 - Loss: 0.1042\n[Epoch 35] Step 650/737 - Loss: 0.1378\n[Epoch 35] Step 700/737 - Loss: 0.1778\nEpoch 035 | TrainLoss(step): 0.1230 | TrainLoss(eval): 0.1044 | ValLoss: 0.9158 | Train mIoU: 0.7455 | Val mIoU: 0.3058 | Val Dice: 2.6798 | Val F1: 0.4398 | Val Acc: 0.7941 | LR: 0.000001\n\n===== Epoch 36/40 =====\n[Epoch 36] Step 1/737 - Loss: 0.0849\n[Epoch 36] Step 50/737 - Loss: 0.1301\n[Epoch 36] Step 100/737 - Loss: 0.1465\n[Epoch 36] Step 150/737 - Loss: 0.1499\n[Epoch 36] Step 200/737 - Loss: 0.1394\n[Epoch 36] Step 250/737 - Loss: 0.0951\n[Epoch 36] Step 300/737 - Loss: 0.0723\n[Epoch 36] Step 350/737 - Loss: 0.1285\n[Epoch 36] Step 400/737 - Loss: 0.1385\n[Epoch 36] Step 450/737 - Loss: 0.0966\n[Epoch 36] Step 500/737 - Loss: 0.1458\n[Epoch 36] Step 550/737 - Loss: 0.1143\n[Epoch 36] Step 600/737 - Loss: 0.1108\n[Epoch 36] Step 650/737 - Loss: 0.1311\n[Epoch 36] Step 700/737 - Loss: 0.0730\nEpoch 036 | TrainLoss(step): 0.1231 | TrainLoss(eval): 0.1043 | ValLoss: 0.9112 | Train mIoU: 0.7456 | Val mIoU: 0.3026 | Val Dice: 2.6458 | Val F1: 0.4350 | Val Acc: 0.7958 | LR: 0.000000\n  -> Checkpoint saved to deeplab_checkpoint_epoch_36.pth\n\n===== Epoch 37/40 =====\n[Epoch 37] Step 1/737 - Loss: 0.1247\n[Epoch 37] Step 50/737 - Loss: 0.1439\n[Epoch 37] Step 100/737 - Loss: 0.1019\n[Epoch 37] Step 150/737 - Loss: 0.0997\n[Epoch 37] Step 200/737 - Loss: 0.1220\n[Epoch 37] Step 250/737 - Loss: 0.0688\n[Epoch 37] Step 300/737 - Loss: 0.1386\n[Epoch 37] Step 350/737 - Loss: 0.1758\n[Epoch 37] Step 400/737 - Loss: 0.0885\n[Epoch 37] Step 450/737 - Loss: 0.0774\n[Epoch 37] Step 500/737 - Loss: 0.1230\n[Epoch 37] Step 550/737 - Loss: 0.0731\n[Epoch 37] Step 600/737 - Loss: 0.0950\n[Epoch 37] Step 650/737 - Loss: 0.1367\n[Epoch 37] Step 700/737 - Loss: 0.0963\nEpoch 037 | TrainLoss(step): 0.1233 | TrainLoss(eval): 0.1032 | ValLoss: 0.9037 | Train mIoU: 0.7497 | Val mIoU: 0.3012 | Val Dice: 2.6900 | Val F1: 0.4333 | Val Acc: 0.7916 | LR: 0.000000\n\n===== Epoch 38/40 =====\n[Epoch 38] Step 1/737 - Loss: 0.1096\n[Epoch 38] Step 50/737 - Loss: 0.1196\n[Epoch 38] Step 100/737 - Loss: 0.1014\n[Epoch 38] Step 150/737 - Loss: 0.0806\n[Epoch 38] Step 200/737 - Loss: 0.1343\n[Epoch 38] Step 250/737 - Loss: 0.0833\n[Epoch 38] Step 300/737 - Loss: 0.0481\n[Epoch 38] Step 350/737 - Loss: 0.1236\n[Epoch 38] Step 400/737 - Loss: 0.1404\n[Epoch 38] Step 450/737 - Loss: 0.1182\n[Epoch 38] Step 500/737 - Loss: 0.0743\n[Epoch 38] Step 550/737 - Loss: 0.1439\n[Epoch 38] Step 600/737 - Loss: 0.1495\n[Epoch 38] Step 650/737 - Loss: 0.1185\n[Epoch 38] Step 700/737 - Loss: 0.0750\nEpoch 038 | TrainLoss(step): 0.1229 | TrainLoss(eval): 0.1046 | ValLoss: 0.9033 | Train mIoU: 0.7461 | Val mIoU: 0.3061 | Val Dice: 2.6939 | Val F1: 0.4406 | Val Acc: 0.7922 | LR: 0.000000\n  -> Checkpoint saved to deeplab_checkpoint_epoch_38.pth\n\n===== Epoch 39/40 =====\n[Epoch 39] Step 1/737 - Loss: 0.1089\n[Epoch 39] Step 50/737 - Loss: 0.1111\n[Epoch 39] Step 100/737 - Loss: 0.1747\n[Epoch 39] Step 150/737 - Loss: 0.1330\n[Epoch 39] Step 200/737 - Loss: 0.0892\n[Epoch 39] Step 250/737 - Loss: 0.1277\n[Epoch 39] Step 300/737 - Loss: 0.0957\n[Epoch 39] Step 350/737 - Loss: 0.1083\n[Epoch 39] Step 400/737 - Loss: 0.1255\n[Epoch 39] Step 450/737 - Loss: 0.1619\n[Epoch 39] Step 500/737 - Loss: 0.1309\n[Epoch 39] Step 550/737 - Loss: 0.1109\n[Epoch 39] Step 600/737 - Loss: 0.1201\n[Epoch 39] Step 650/737 - Loss: 0.1221\n[Epoch 39] Step 700/737 - Loss: 0.1148\nEpoch 039 | TrainLoss(step): 0.1226 | TrainLoss(eval): 0.1034 | ValLoss: 0.8961 | Train mIoU: 0.7490 | Val mIoU: 0.3066 | Val Dice: 2.6820 | Val F1: 0.4409 | Val Acc: 0.7924 | LR: 0.000000\n\n===== Epoch 40/40 =====\n[Epoch 40] Step 1/737 - Loss: 0.1000\n[Epoch 40] Step 50/737 - Loss: 0.1196\n[Epoch 40] Step 100/737 - Loss: 0.1069\n[Epoch 40] Step 150/737 - Loss: 0.1780\n[Epoch 40] Step 200/737 - Loss: 0.0908\n[Epoch 40] Step 250/737 - Loss: 0.0749\n[Epoch 40] Step 300/737 - Loss: 0.1011\n[Epoch 40] Step 350/737 - Loss: 0.1481\n[Epoch 40] Step 400/737 - Loss: 0.1190\n[Epoch 40] Step 450/737 - Loss: 0.1190\n[Epoch 40] Step 500/737 - Loss: 0.1117\n[Epoch 40] Step 550/737 - Loss: 0.1463\n[Epoch 40] Step 600/737 - Loss: 0.1105\n[Epoch 40] Step 650/737 - Loss: 0.3725\n[Epoch 40] Step 700/737 - Loss: 0.1029\nEpoch 040 | TrainLoss(step): 0.1235 | TrainLoss(eval): 0.1035 | ValLoss: 0.9046 | Train mIoU: 0.7465 | Val mIoU: 0.3039 | Val Dice: 2.7074 | Val F1: 0.4370 | Val Acc: 0.7906 | LR: 0.000000\n  -> Checkpoint saved to deeplab_checkpoint_epoch_40.pth\n\nTraining complete. Best mIoU: 0.3128804564476013\nSaved metrics to: /kaggle/working/deeplab_results.json\n","output_type":"stream"},{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/deeplab_results.json","text/html":"<a href='/kaggle/working/deeplab_results.json' target='_blank'>/kaggle/working/deeplab_results.json</a><br>"},"metadata":{}}],"execution_count":15}]}